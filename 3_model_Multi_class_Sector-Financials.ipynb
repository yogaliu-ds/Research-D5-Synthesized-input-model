{"cells":[{"cell_type":"markdown","metadata":{"id":"iiiO7bcHN_Ao"},"source":["# 0 Setting"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4642,"status":"ok","timestamp":1699866070035,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"},"user_tz":-540},"id":"aWHVuAauNB5o","outputId":"6ff0e749-8684-4876-e0b4-0527a6362801"},"outputs":[{"output_type":"stream","name":"stdout","text":["11\n"]}],"source":["# Parameter Setting\n","import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","folder_name = 'Research-(D5) Synthesized input model'\n","pretrained_model_name = 'model_microsoft.ckpt'\n","\n","config = {\n","    'learning_rate': 5e-4,\n","    'batch_size': 32,\n","    'seq_length': 5,\n","\n","    'shuffle': False,\n","    'criterion': torch.nn.CrossEntropyLoss(),\n","    'seed': 42,\n","\n","    'n_epochs': 3000,\n","    'early_stop': 500,\n","    'device': device,\n","}\n","\n","\n","sector_id_list = [ # Not confirmed\n","    \"XLK\",  # Information Technology\n","    \"XLV\",  # Health Care\n","    \"XLF\",  # Financials\n","    \"XLI\",  # Industrials\n","    \"XLY\",  # Consumer Discretionary\n","    \"XLE\",  # Energy\n","    \"XLB\",  # Materials\n","    \"XLC\",  # Communication Services\n","    \"XLU\",  # Utilities\n","    \"XLRE\",  # Real Estate\n","    \"XLP\"  # Consumer Staples\n","]\n","\n","company_list = [\n","    \"Information Technology\",\n","    \"Health Care\",\n","    \"Financials\",\n","    \"Industrials\",\n","    \"Consumer Discretionary\",\n","    \"Energy\",\n","    \"Materials\",\n","    \"Communication Services\",\n","    \"Utilities\",\n","    \"Real Estate\",\n","    \"Consumer Staples\"\n","]\n","\n","process_id = 2  #26\n","\n","company_name = company_list[process_id]\n","\n","config_2 = {'input_path': '/content/drive/MyDrive/Colab Notebooks/'+folder_name+'/data/2_'+company_name+'_for_model.csv',\n","            'save_path': '/content/drive/MyDrive/Colab Notebooks/'+folder_name+'/model_saved/model_'+company_name+'.ckpt',\n","            # 'pretrained_model_path': '/content/drive/MyDrive/Colab Notebooks/'+folder_name+'/premodel/' + pretrained_model_name,\n","            # 'continue_model_path': '/content/drive/MyDrive/Colab Notebooks/'+folder_name+'/model_saved/model_1.ckpt'\n","            }\n","\n","feature = [\n","    # X_1\n","    'input_ids',\n","    'attention_mask',\n","    'section_dummy',\n","    'publication_dummy',\n","\n","    # X_2\n","    # 1. tech indicator\n","    # 'Open',\n","    # 'High',\n","    # 'Low',\n","    # 'Close',\n","    # 'Volume',\n","    # 'Dividends',\n","    # 'Stock Splits',\n","    'today_return',\n","    # 'today_return_cate',\n","    # 'Sma',\n","    # 'Rsi',\n","    # 'Kd',\n","    # 'Ema_12',\n","    # 'Ema_26',\n","    # 'Macd',\n","    # 'sentiment',\n","\n","    # 2. market index\n","    '^DJI',\n","    '^GSPC',\n","    '^NDX',\n","    '^IXIC',\n","    '^SOX',\n","    '^NYA',\n","\n","    # y\n","    # '1_day_return',\n","    # '2_day_return',\n","    # '3_day_return',\n","    # '4_day_return',\n","    # '5_day_return',\n","    # '1_day_return_cate',\n","    # '2_day_return_cate',\n","    # '3_day_return_cate',\n","    # '4_day_return_cate',\n","    # '5_day_return_cate',\n","    # '^DJI', '^DJI_1_day_return', '^GSPC', '^GSPC_1_day_return',\n","    #    '^NDX', '^NDX_1_day_return', '^IXIC', '^IXIC_1_day_return', '^SOX',\n","    #    '^SOX_1_day_return',\n","    # 'excess_return_^DJI',\n","    # 'excess_return_^DJI_cate',\n","    # 'excess_return_^GSPC',\n","    'excess_return_^GSPC_cate',\n","    # 'excess_return_^NDX',\n","    # 'excess_return_^NDX_cate',\n","    # 'excess_return_^IXIC',\n","    # 'excess_return_^IXIC_cate',\n","    # 'excess_return_^SOX',\n","    # 'excess_return_^SOX_cate',\n","\n","    # Do not mark the datetime, it's for operation\n","    'datetime',\n","    ]\n","\n","# All the news dataset\n","# time_start = '2016-01-01T00:00:00'\n","# time_end = '2020-04-02T00:00:00'\n","\n","time_start = '2016-01-01T00:00:00'\n","time_end = '2019-12-31T00:00:00'\n","\n","print(len(feature)-2)"]},{"cell_type":"markdown","metadata":{"id":"Paj5_XoohZwu"},"source":["## (1) Import"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ca00OwVROzyQ","outputId":"f707bae3-be6a-4d66-e010-7825e512f099","executionInfo":{"status":"ok","timestamp":1699866125945,"user_tz":-540,"elapsed":55923,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting transformers\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"]}],"source":["# Google\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# pip installation\n","!pip install transformers\n","\n","# Basic\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","\n","# Sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n","\n","# PyTorch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from transformers import BertTokenizer, BertModel, BertConfig\n","\n","# others\n","from datetime import datetime, timedelta\n","from tqdm import tqdm\n","from torchsummary import summary\n","import ast"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hnPf7jxjPPDL","executionInfo":{"status":"ok","timestamp":1699866125947,"user_tz":-540,"elapsed":41,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["def same_seed(seed):\n","    '''Fixes random number generator seeds for reproducibility.'''\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","# Set seed for reproducibility\n","same_seed(config['seed'])\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zH3oxSTkO85T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128880,"user_tz":-540,"elapsed":2968,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"023b83cc-5257-4e40-e4ab-7e91fce01d39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits',\n","       'Capital Gains', 'today_return', 'today_return_cate', '1_day_return',\n","       '2_day_return', '3_day_return', '4_day_return', '5_day_return',\n","       '1_day_return_cate', '2_day_return_cate', '3_day_return_cate',\n","       '4_day_return_cate', '5_day_return_cate', 'Sma', 'Rsi', 'Kd', 'Ema_12',\n","       'Ema_26', 'Macd', 'datetime', '^DJI', '^DJI_1_day_return', '^GSPC',\n","       '^GSPC_1_day_return', '^NDX', '^NDX_1_day_return', '^IXIC',\n","       '^IXIC_1_day_return', '^SOX', '^SOX_1_day_return', '^NYA',\n","       '^NYA_1_day_return', 'excess_return_^DJI', 'excess_return_^DJI_cate',\n","       'excess_return_^GSPC', 'excess_return_^GSPC_cate', 'excess_return_^NDX',\n","       'excess_return_^NDX_cate', 'excess_return_^IXIC',\n","       'excess_return_^IXIC_cate', 'excess_return_^SOX',\n","       'excess_return_^SOX_cate', 'excess_return_^NYA',\n","       'excess_return_^NYA_cate', 'input_ids', 'attention_mask',\n","       'section_dummy', 'publication_dummy', 'sentiment'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}],"source":["df = pd.read_csv(config_2['input_path'])\n","df.columns"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"184Zrsi8LD02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128881,"user_tz":-540,"elapsed":84,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"cfbc9230-f84d-4206-e1ad-22f2bccca6db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1070, 56)"]},"metadata":{},"execution_count":5}],"source":["df = df.sort_values(by='datetime', ascending=True)\n","df.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"11JAV-xePHKF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128882,"user_tz":-540,"elapsed":71,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"b4e792a6-1ce7-4e6c-c738-15eb9ce9b171"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['input_ids', 'attention_mask', 'section_dummy', 'publication_dummy',\n","       'today_return', '^DJI', '^GSPC', '^NDX', '^IXIC', '^SOX', '^NYA',\n","       'excess_return_^GSPC_cate', 'datetime'],\n","      dtype='object')"]},"metadata":{},"execution_count":6}],"source":["# Only contain selected features\n","df = df[feature]\n","df.columns"]},{"cell_type":"markdown","metadata":{"id":"Vkha6OadTpMA"},"source":["## (2) check nan"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QKx4PK-UEgb7","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1699866128882,"user_tz":-540,"elapsed":61,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"853d59a1-1909-40f8-b89d-8af800431919"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [input_ids, attention_mask, section_dummy, publication_dummy, today_return, ^DJI, ^GSPC, ^NDX, ^IXIC, ^SOX, ^NYA, excess_return_^GSPC_cate, datetime]\n","Index: []"],"text/html":["\n","  <div id=\"df-383a477c-9e5e-41dd-b0cd-c5c17965cabb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>section_dummy</th>\n","      <th>publication_dummy</th>\n","      <th>today_return</th>\n","      <th>^DJI</th>\n","      <th>^GSPC</th>\n","      <th>^NDX</th>\n","      <th>^IXIC</th>\n","      <th>^SOX</th>\n","      <th>^NYA</th>\n","      <th>excess_return_^GSPC_cate</th>\n","      <th>datetime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-383a477c-9e5e-41dd-b0cd-c5c17965cabb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-383a477c-9e5e-41dd-b0cd-c5c17965cabb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-383a477c-9e5e-41dd-b0cd-c5c17965cabb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}],"source":["df[df.isna().any(axis=1)]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nhfwhVrqTrY5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128883,"user_tz":-540,"elapsed":55,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"46cf8208-63bf-4643-eec7-b66be17d63b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["input_ids                   0\n","attention_mask              0\n","section_dummy               0\n","publication_dummy           0\n","today_return                0\n","^DJI                        0\n","^GSPC                       0\n","^NDX                        0\n","^IXIC                       0\n","^SOX                        0\n","^NYA                        0\n","excess_return_^GSPC_cate    0\n","datetime                    0\n","dtype: int64"]},"metadata":{},"execution_count":8}],"source":["df.isnull().sum()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"w4i2TznkTs5o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128884,"user_tz":-540,"elapsed":43,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"48b6823e-30b8-45e7-be86-013d87fc516d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["input_ids                   0\n","attention_mask              0\n","section_dummy               0\n","publication_dummy           0\n","today_return                0\n","^DJI                        0\n","^GSPC                       0\n","^NDX                        0\n","^IXIC                       0\n","^SOX                        0\n","^NYA                        0\n","excess_return_^GSPC_cate    0\n","datetime                    0\n","dtype: int64"]},"metadata":{},"execution_count":9}],"source":["df = df.dropna()\n","df = df.reset_index(drop=True)\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"qtUEqIEXkOHE"},"source":["## (2) Time Period Selection"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"09E8ivNfPwtB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866128885,"user_tz":-540,"elapsed":32,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"88930e03-ee56-480a-e074-71dfcc627861"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1006, 12)"]},"metadata":{},"execution_count":10}],"source":["# We use index to filter for time periods\n","df = df[(df['datetime']> time_start) & (df['datetime'] < time_end)]\n","\n","# Drop datetime after using it\n","df.drop(columns=['datetime'], inplace=True)\n","df.shape"]},{"cell_type":"markdown","metadata":{"id":"7rdZgCpbe8DQ"},"source":["## (3) Transform str back to list"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"WDujbxYKe6qj","executionInfo":{"status":"ok","timestamp":1699866140107,"user_tz":-540,"elapsed":10693,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# 将字符串转换回列表的函数\n","def string_to_list(s):\n","    return ast.literal_eval(s)\n","\n","# 将列中的字符串转换回列表\n","df['input_ids'] = df['input_ids'].apply(string_to_list)\n","df['attention_mask'] = df['attention_mask'].apply(string_to_list)\n","df['section_dummy'] = df['section_dummy'].apply(string_to_list)\n","df['publication_dummy'] = df['publication_dummy'].apply(string_to_list)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"zGHAxc3oGUjH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866140108,"user_tz":-540,"elapsed":45,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"3a46ef10-babe-4081-e7ab-8a7b14fd0d29"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[101,\n"," 2376,\n"," 2491,\n"," 2115,\n"," 21074,\n"," 2013,\n"," 2115,\n"," 7513,\n"," 2316,\n"," 1016,\n"," 102,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"metadata":{},"execution_count":12}],"source":["df['input_ids'][0][0]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"IMoH702QNmLZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866140109,"user_tz":-540,"elapsed":33,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"61143383-6fce-4dd6-a2a3-d9e34195d5dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"metadata":{},"execution_count":13}],"source":["df['attention_mask'][0][0]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CeeEKFq5NpC3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866140110,"user_tz":-540,"elapsed":24,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"23344723-116f-42a5-9d2a-30b53d20defd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 0, 0, 0, 1, 0, 0, 0]"]},"metadata":{},"execution_count":14}],"source":["df['section_dummy'][0][0]"]},{"cell_type":"markdown","metadata":{"id":"tzhAx562jOlb"},"source":["## (3) List: Same amount of elements"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"BBwY00GFymVO","executionInfo":{"status":"ok","timestamp":1699866140111,"user_tz":-540,"elapsed":18,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["input_ids_list_length = len(df['input_ids'][0][0])\n","attention_mask_list_length = len(df['attention_mask'][0][0])\n","section_dummy_list_length = len(df['section_dummy'][0][0])\n","publication_dummy_list_length = len(df['publication_dummy'][0][0])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"-mGgQZ6ojU5c","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1699866140877,"user_tz":-540,"elapsed":782,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"5f29d076-e1b5-4cc7-f23a-ae93ef771311"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              input_ids  \\\n","0     [[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...   \n","1     [[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...   \n","2     [[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...   \n","3     [[101, 15837, 10554, 1010, 12806, 6063, 1010, ...   \n","4     [[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...   \n","...                                                 ...   \n","1001  [[101, 26060, 1521, 1055, 6209, 4007, 10651, 2...   \n","1002  [[101, 2260, 2190, 2044, 1011, 4234, 4341, 100...   \n","1003  [[101, 2047, 2095, 1005, 1055, 18853, 1010, 20...   \n","1004  [[101, 6239, 3488, 4964, 9883, 2005, 1041, 101...   \n","1005  [[101, 7596, 18989, 1010, 9109, 2000, 7733, 19...   \n","\n","                                         attention_mask  \\\n","0     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...   \n","1     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","2     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","3     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","4     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...   \n","...                                                 ...   \n","1001  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","1002  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","1003  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...   \n","1004  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...   \n","1005  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","\n","                                          section_dummy  \\\n","0     [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","1     [[0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","2     [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","3     [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...   \n","4     [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...   \n","...                                                 ...   \n","1001  [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...   \n","1002  [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","1003  [[0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","1004  [[0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, ...   \n","1005  [[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...   \n","\n","                                      publication_dummy  today_return  \\\n","0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...      0.001285   \n","1     [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, ...      0.002136   \n","2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...     -0.000865   \n","3     [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, ...     -0.007516   \n","4     [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, ...     -0.024283   \n","...                                                 ...           ...   \n","1001  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...      0.000326   \n","1002  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, ...      0.004559   \n","1003  [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, ...     -0.004207   \n","1004  [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, ...     -0.007441   \n","1005  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, ...      0.003914   \n","\n","          ^DJI     ^GSPC      ^NDX     ^IXIC      ^SOX      ^NYA  \\\n","0    -0.014739 -0.012531  0.002854  0.001111  0.008979 -0.001845   \n","1     0.000651  0.001455 -0.006175 -0.005370 -0.012003  0.002104   \n","2    -0.014475 -0.010663  0.007758  0.004570 -0.011092 -0.003948   \n","3    -0.022161 -0.021271 -0.009984 -0.009917 -0.010667 -0.010350   \n","4    -0.010456 -0.012302 -0.015069 -0.016601 -0.019801 -0.016923   \n","...        ...       ...       ...       ...       ...       ...   \n","1001 -0.001999 -0.000642 -0.000665 -0.000238  0.001204 -0.000562   \n","1002  0.002871  0.003938  0.006924  0.005817 -0.000499  0.002103   \n","1003 -0.001049 -0.002220 -0.003961 -0.004735 -0.006431 -0.002340   \n","1004 -0.006722 -0.005802 -0.006463 -0.006492 -0.006593 -0.005384   \n","1005  0.004357  0.004852  0.005960  0.006039  0.007320  0.004362   \n","\n","      excess_return_^GSPC_cate  \n","0                            1  \n","1                            1  \n","2                            1  \n","3                            0  \n","4                            0  \n","...                        ...  \n","1001                         1  \n","1002                         0  \n","1003                         0  \n","1004                         0  \n","1005                         1  \n","\n","[1006 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-d00756df-a6ec-4406-b7aa-04d7ca69f152\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>section_dummy</th>\n","      <th>publication_dummy</th>\n","      <th>today_return</th>\n","      <th>^DJI</th>\n","      <th>^GSPC</th>\n","      <th>^NDX</th>\n","      <th>^IXIC</th>\n","      <th>^SOX</th>\n","      <th>^NYA</th>\n","      <th>excess_return_^GSPC_cate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...</td>\n","      <td>0.001285</td>\n","      <td>-0.014739</td>\n","      <td>-0.012531</td>\n","      <td>0.002854</td>\n","      <td>0.001111</td>\n","      <td>0.008979</td>\n","      <td>-0.001845</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, ...</td>\n","      <td>0.002136</td>\n","      <td>0.000651</td>\n","      <td>0.001455</td>\n","      <td>-0.006175</td>\n","      <td>-0.005370</td>\n","      <td>-0.012003</td>\n","      <td>0.002104</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...</td>\n","      <td>-0.000865</td>\n","      <td>-0.014475</td>\n","      <td>-0.010663</td>\n","      <td>0.007758</td>\n","      <td>0.004570</td>\n","      <td>-0.011092</td>\n","      <td>-0.003948</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[101, 15837, 10554, 1010, 12806, 6063, 1010, ...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, ...</td>\n","      <td>-0.007516</td>\n","      <td>-0.022161</td>\n","      <td>-0.021271</td>\n","      <td>-0.009984</td>\n","      <td>-0.009917</td>\n","      <td>-0.010667</td>\n","      <td>-0.010350</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, ...</td>\n","      <td>-0.024283</td>\n","      <td>-0.010456</td>\n","      <td>-0.012302</td>\n","      <td>-0.015069</td>\n","      <td>-0.016601</td>\n","      <td>-0.019801</td>\n","      <td>-0.016923</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1001</th>\n","      <td>[[101, 26060, 1521, 1055, 6209, 4007, 10651, 2...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, ...</td>\n","      <td>0.000326</td>\n","      <td>-0.001999</td>\n","      <td>-0.000642</td>\n","      <td>-0.000665</td>\n","      <td>-0.000238</td>\n","      <td>0.001204</td>\n","      <td>-0.000562</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1002</th>\n","      <td>[[101, 2260, 2190, 2044, 1011, 4234, 4341, 100...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, ...</td>\n","      <td>0.004559</td>\n","      <td>0.002871</td>\n","      <td>0.003938</td>\n","      <td>0.006924</td>\n","      <td>0.005817</td>\n","      <td>-0.000499</td>\n","      <td>0.002103</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1003</th>\n","      <td>[[101, 2047, 2095, 1005, 1055, 18853, 1010, 20...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, ...</td>\n","      <td>-0.004207</td>\n","      <td>-0.001049</td>\n","      <td>-0.002220</td>\n","      <td>-0.003961</td>\n","      <td>-0.004735</td>\n","      <td>-0.006431</td>\n","      <td>-0.002340</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1004</th>\n","      <td>[[101, 6239, 3488, 4964, 9883, 2005, 1041, 101...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, ...</td>\n","      <td>-0.007441</td>\n","      <td>-0.006722</td>\n","      <td>-0.005802</td>\n","      <td>-0.006463</td>\n","      <td>-0.006492</td>\n","      <td>-0.006593</td>\n","      <td>-0.005384</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1005</th>\n","      <td>[[101, 7596, 18989, 1010, 9109, 2000, 7733, 19...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, ...</td>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, ...</td>\n","      <td>0.003914</td>\n","      <td>0.004357</td>\n","      <td>0.004852</td>\n","      <td>0.005960</td>\n","      <td>0.006039</td>\n","      <td>0.007320</td>\n","      <td>0.004362</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1006 rows × 12 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d00756df-a6ec-4406-b7aa-04d7ca69f152')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d00756df-a6ec-4406-b7aa-04d7ca69f152 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d00756df-a6ec-4406-b7aa-04d7ca69f152');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8730886a-f763-46ca-9f45-bda6e6c5dbff\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8730886a-f763-46ca-9f45-bda6e6c5dbff')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8730886a-f763-46ca-9f45-bda6e6c5dbff button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7b83299e-7dd6-4101-b437-047918555f45\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7b83299e-7dd6-4101-b437-047918555f45 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":16}],"source":["# 找到最大的內部列表長度\n","max_inner_length = max(df['input_ids'].apply(len))\n","\n","# 定義一個函數來填充內部列表，使其長度達到最大值\n","def pad_inner_list(lst, zero_list):\n","    while len(lst) < max_inner_length:\n","        lst.append(zero_list)  # 這裡可以填充任何你想要的值，例如 None\n","\n","# 將 \"input_ids\" 列中的每個內部列表填充到最大長度\n","df['input_ids'].apply(pad_inner_list, zero_list=[0] * input_ids_list_length)\n","df['attention_mask'].apply(pad_inner_list, zero_list=[0] * attention_mask_list_length)\n","df['section_dummy'].apply(pad_inner_list, zero_list=[0] * section_dummy_list_length)\n","df['publication_dummy'].apply(pad_inner_list, zero_list=[0] * publication_dummy_list_length)\n","df"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"rGW3R5I-zoAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866140879,"user_tz":-540,"elapsed":54,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"11fdf398-4b20-4772-af43-7f7f78dc6bec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 1, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 1, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 1, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 1, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 1],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 1, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":17}],"source":["df['section_dummy'][0]"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"nemqwoqfj5gM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866141859,"user_tz":-540,"elapsed":1005,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"f52ebd7a-0fca-4026-a9ec-d9d0c40457ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       124\n","1       124\n","2       124\n","3       124\n","4       124\n","       ... \n","1001    124\n","1002    124\n","1003    124\n","1004    124\n","1005    124\n","Name: input_ids, Length: 1006, dtype: int64"]},"metadata":{},"execution_count":18}],"source":["# 使用 apply 方法計算每個列表中元素的數量\n","# Note: This number is not about tokens. It's about the number of news in that day.\n","temp = df['input_ids'].apply(len)\n","\n","# 打印 DataFrame\n","temp"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"gjCUj07CIYtP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866141860,"user_tz":-540,"elapsed":28,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"b9376de2-3468-4012-c075-8cd2eca6c48b"},"outputs":[{"output_type":"stream","name":"stdout","text":["平均長度: 124.0\n","最長長度: 124\n","最短長度: 124\n"]}],"source":["# 計算\"input_ids\"列中所有list的平均長度\n","average_length = df['input_ids'].apply(len).mean()\n","\n","# 計算\"input_ids\"列中最長的list的長度\n","max_length = df['input_ids'].apply(len).max()\n","\n","# 計算\"input_ids\"列中最短的list的長度\n","min_length = df['input_ids'].apply(len).min()\n","\n","# 打印結果\n","print(f\"平均長度: {average_length}\")\n","print(f\"最長長度: {max_length}\")\n","print(f\"最短長度: {min_length}\")\n"]},{"cell_type":"markdown","metadata":{"id":"2GqgLTLStucf"},"source":["## int to float (section, publication)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Le2gfI67Mel-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866141861,"user_tz":-540,"elapsed":21,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"a893b855-1b04-4fc7-84d0-652a43ca3f69"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":20}],"source":["type(df.input_ids[0][0])"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"XhEV-SK6tak0","executionInfo":{"status":"ok","timestamp":1699866143114,"user_tz":-540,"elapsed":1267,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["def recursive_convert_to_float(item):\n","    if isinstance(item, list):\n","        return [recursive_convert_to_float(x) if x is not None else None for x in item]\n","    else:\n","        return float(item) if item is not None else None\n","\n","# 使用 apply 方法將函數應用於每個元素\n","df['section_dummy'] = df['section_dummy'].apply(recursive_convert_to_float)\n","df['publication_dummy'] = df['publication_dummy'].apply(recursive_convert_to_float)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Nowtpnj4tzgo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866143116,"user_tz":-540,"elapsed":59,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"aa4b3470-76de-487e-c875-352a2b9568a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n"," [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]"]},"metadata":{},"execution_count":22}],"source":["df['section_dummy'][0]"]},{"cell_type":"markdown","metadata":{"id":"4Q7dnpuMeJGj"},"source":["## (4) Train_test_split"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"-lNUztpwP1pY","executionInfo":{"status":"ok","timestamp":1699866143117,"user_tz":-540,"elapsed":35,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# 1. Set up X, y\n","to_remove_list = ['datetime', 'excess_return_^GSPC_cate']\n","\n","# Filter out values in to_remove_list\n","filtered_list = [x for x in feature if x not in to_remove_list]\n","\n","X = df[filtered_list]\n","y = df['excess_return_^GSPC_cate']"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TuCa3Cs0P4lN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866143117,"user_tz":-540,"elapsed":34,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"39fb1042-c00d-4a8a-8646-2e0b9d8b7cdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["X: (1006, 11)\n","y: (1006,)\n"]}],"source":["# Check X, y shape\n","print('X:', X.shape)\n","print('y:', y.shape)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"NBW9qnq5QASt","colab":{"base_uri":"https://localhost:8080/","height":945},"executionInfo":{"status":"ok","timestamp":1699866143790,"user_tz":-540,"elapsed":693,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"2dd7c01a-0d1d-4857-dc6a-4404e6b55aca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             input_ids  \\\n","0    [[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...   \n","1    [[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...   \n","2    [[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...   \n","3    [[101, 15837, 10554, 1010, 12806, 6063, 1010, ...   \n","4    [[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...   \n","..                                                 ...   \n","598  [[101, 2156, 12669, 4819, 2928, 2571, 1005, 10...   \n","599  [[101, 2739, 2651, 1024, 11382, 12096, 6460, 2...   \n","600  [[101, 1019, 2477, 2005, 2089, 2603, 1024, 216...   \n","601  [[101, 27166, 9818, 7262, 1024, 27166, 9818, 2...   \n","602  [[101, 3534, 4153, 2838, 1999, 2047, 2548, 292...   \n","\n","                                        attention_mask  \\\n","0    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...   \n","1    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","2    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","3    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","4    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...   \n","..                                                 ...   \n","598  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","599  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","600  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","601  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","602  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","\n","                                         section_dummy  \\\n","0    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","1    [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","2    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","3    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","4    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","..                                                 ...   \n","598  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","599  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","600  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","601  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","602  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","\n","                                     publication_dummy  today_return  \\\n","0    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.001285   \n","1    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0.002136   \n","2    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     -0.000865   \n","3    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...     -0.007516   \n","4    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...     -0.024283   \n","..                                                 ...           ...   \n","598  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...     -0.008162   \n","599  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.001423   \n","600  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.006035   \n","601  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.000355   \n","602  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...     -0.004631   \n","\n","         ^DJI     ^GSPC      ^NDX     ^IXIC      ^SOX      ^NYA  \n","0   -0.014739 -0.012531  0.002854  0.001111  0.008979 -0.001845  \n","1    0.000651  0.001455 -0.006175 -0.005370 -0.012003  0.002104  \n","2   -0.014475 -0.010663  0.007758  0.004570 -0.011092 -0.003948  \n","3   -0.022161 -0.021271 -0.009984 -0.009917 -0.010667 -0.010350  \n","4   -0.010456 -0.012302 -0.015069 -0.016601 -0.019801 -0.016923  \n","..        ...       ...       ...       ...       ...       ...  \n","598  0.000298 -0.001612 -0.001512 -0.001358 -0.003253 -0.001389  \n","599  0.005234 -0.000870 -0.002137 -0.001661 -0.004453  0.002540  \n","600 -0.008509 -0.005076 -0.005924 -0.005712 -0.001986 -0.005106  \n","601  0.005215  0.007115  0.015533  0.012397  0.015664  0.003293  \n","602 -0.002637 -0.001164 -0.000262  0.000329  0.003705 -0.001464  \n","\n","[603 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-1778fed2-bff4-4cc7-803c-2bbe4a83d92e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>section_dummy</th>\n","      <th>publication_dummy</th>\n","      <th>today_return</th>\n","      <th>^DJI</th>\n","      <th>^GSPC</th>\n","      <th>^NDX</th>\n","      <th>^IXIC</th>\n","      <th>^SOX</th>\n","      <th>^NYA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.001285</td>\n","      <td>-0.014739</td>\n","      <td>-0.012531</td>\n","      <td>0.002854</td>\n","      <td>0.001111</td>\n","      <td>0.008979</td>\n","      <td>-0.001845</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>0.002136</td>\n","      <td>0.000651</td>\n","      <td>0.001455</td>\n","      <td>-0.006175</td>\n","      <td>-0.005370</td>\n","      <td>-0.012003</td>\n","      <td>0.002104</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>-0.000865</td>\n","      <td>-0.014475</td>\n","      <td>-0.010663</td>\n","      <td>0.007758</td>\n","      <td>0.004570</td>\n","      <td>-0.011092</td>\n","      <td>-0.003948</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[101, 15837, 10554, 1010, 12806, 6063, 1010, ...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>-0.007516</td>\n","      <td>-0.022161</td>\n","      <td>-0.021271</td>\n","      <td>-0.009984</td>\n","      <td>-0.009917</td>\n","      <td>-0.010667</td>\n","      <td>-0.010350</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...</td>\n","      <td>-0.024283</td>\n","      <td>-0.010456</td>\n","      <td>-0.012302</td>\n","      <td>-0.015069</td>\n","      <td>-0.016601</td>\n","      <td>-0.019801</td>\n","      <td>-0.016923</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>[[101, 2156, 12669, 4819, 2928, 2571, 1005, 10...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>-0.008162</td>\n","      <td>0.000298</td>\n","      <td>-0.001612</td>\n","      <td>-0.001512</td>\n","      <td>-0.001358</td>\n","      <td>-0.003253</td>\n","      <td>-0.001389</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>[[101, 2739, 2651, 1024, 11382, 12096, 6460, 2...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.001423</td>\n","      <td>0.005234</td>\n","      <td>-0.000870</td>\n","      <td>-0.002137</td>\n","      <td>-0.001661</td>\n","      <td>-0.004453</td>\n","      <td>0.002540</td>\n","    </tr>\n","    <tr>\n","      <th>600</th>\n","      <td>[[101, 1019, 2477, 2005, 2089, 2603, 1024, 216...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.006035</td>\n","      <td>-0.008509</td>\n","      <td>-0.005076</td>\n","      <td>-0.005924</td>\n","      <td>-0.005712</td>\n","      <td>-0.001986</td>\n","      <td>-0.005106</td>\n","    </tr>\n","    <tr>\n","      <th>601</th>\n","      <td>[[101, 27166, 9818, 7262, 1024, 27166, 9818, 2...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.000355</td>\n","      <td>0.005215</td>\n","      <td>0.007115</td>\n","      <td>0.015533</td>\n","      <td>0.012397</td>\n","      <td>0.015664</td>\n","      <td>0.003293</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>[[101, 3534, 4153, 2838, 1999, 2047, 2548, 292...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...</td>\n","      <td>-0.004631</td>\n","      <td>-0.002637</td>\n","      <td>-0.001164</td>\n","      <td>-0.000262</td>\n","      <td>0.000329</td>\n","      <td>0.003705</td>\n","      <td>-0.001464</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>603 rows × 11 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1778fed2-bff4-4cc7-803c-2bbe4a83d92e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1778fed2-bff4-4cc7-803c-2bbe4a83d92e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1778fed2-bff4-4cc7-803c-2bbe4a83d92e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-03dcf51d-2991-44d4-9d3d-52d1db3300ff\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03dcf51d-2991-44d4-9d3d-52d1db3300ff')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-03dcf51d-2991-44d4-9d3d-52d1db3300ff button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f123bbc5-9ff9-4aa5-bdb4-94355404d1fd\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f123bbc5-9ff9-4aa5-bdb4-94355404d1fd button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('X_train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":25}],"source":["# 2. train_test_split\n","# val dataset for final examination\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=config['seed'], shuffle=config['shuffle'])\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=config['seed'], shuffle=config['shuffle'])\n","\n","# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=config['seed'], shuffle=config['shuffle'])\n","# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.66, random_state=config['seed'], shuffle=config['shuffle'])\n","X_train\n"]},{"cell_type":"markdown","metadata":{"id":"RccwSqS3SOmR"},"source":["## (5) Scaler"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"-wg4fy92Q81E","colab":{"base_uri":"https://localhost:8080/","height":945},"executionInfo":{"status":"ok","timestamp":1699866145450,"user_tz":-540,"elapsed":1676,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"b18ac169-7567-4223-be44-f52179963483"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             input_ids  \\\n","0    [[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...   \n","1    [[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...   \n","2    [[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...   \n","3    [[101, 15837, 10554, 1010, 12806, 6063, 1010, ...   \n","4    [[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...   \n","..                                                 ...   \n","598  [[101, 2156, 12669, 4819, 2928, 2571, 1005, 10...   \n","599  [[101, 2739, 2651, 1024, 11382, 12096, 6460, 2...   \n","600  [[101, 1019, 2477, 2005, 2089, 2603, 1024, 216...   \n","601  [[101, 27166, 9818, 7262, 1024, 27166, 9818, 2...   \n","602  [[101, 3534, 4153, 2838, 1999, 2047, 2548, 292...   \n","\n","                                        attention_mask  \\\n","0    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...   \n","1    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","2    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","3    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","4    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...   \n","..                                                 ...   \n","598  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","599  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","600  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","601  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","602  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n","\n","                                         section_dummy  \\\n","0    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","1    [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","2    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","3    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","4    [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","..                                                 ...   \n","598  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","599  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","600  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...   \n","601  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","602  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...   \n","\n","                                     publication_dummy  today_return  \\\n","0    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.534311   \n","1    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0.543987   \n","2    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.509845   \n","3    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0.434182   \n","4    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...      0.243421   \n","..                                                 ...           ...   \n","598  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0.426829   \n","599  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.535876   \n","600  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.588346   \n","601  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0.523729   \n","602  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...      0.466997   \n","\n","         ^DJI     ^GSPC      ^NDX     ^IXIC      ^SOX      ^NYA  \n","0    0.355624  0.377236  0.525722  0.515721  0.591670  0.548185  \n","1    0.557596  0.578553  0.424253  0.436452  0.374338  0.606119  \n","2    0.359087  0.404126  0.580837  0.558035  0.383766  0.517342  \n","3    0.258224  0.251419  0.381444  0.380842  0.388167  0.423407  \n","4    0.411837  0.380522  0.324291  0.299087  0.293563  0.326980  \n","..        ...       ...       ...       ...       ...       ...  \n","598  0.552968  0.534407  0.476651  0.485527  0.464971  0.554878  \n","599  0.617738  0.545086  0.469628  0.481824  0.452541  0.612522  \n","600  0.437380  0.484541  0.427071  0.432268  0.478096  0.500349  \n","601  0.617488  0.660028  0.668223  0.653762  0.660923  0.623563  \n","602  0.514448  0.540849  0.490705  0.506157  0.537049  0.553786  \n","\n","[603 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-75594a31-adca-48ac-a588-c621cf50b3d8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>section_dummy</th>\n","      <th>publication_dummy</th>\n","      <th>today_return</th>\n","      <th>^DJI</th>\n","      <th>^GSPC</th>\n","      <th>^NDX</th>\n","      <th>^IXIC</th>\n","      <th>^SOX</th>\n","      <th>^NYA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[101, 2376, 2491, 2115, 21074, 2013, 2115, 75...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.534311</td>\n","      <td>0.355624</td>\n","      <td>0.377236</td>\n","      <td>0.525722</td>\n","      <td>0.515721</td>\n","      <td>0.591670</td>\n","      <td>0.548185</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[[101, 2613, 2160, 23744, 1997, 12218, 4564, 1...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>0.543987</td>\n","      <td>0.557596</td>\n","      <td>0.578553</td>\n","      <td>0.424253</td>\n","      <td>0.436452</td>\n","      <td>0.374338</td>\n","      <td>0.606119</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[101, 2182, 1005, 1055, 1996, 2852, 9314, 637...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.509845</td>\n","      <td>0.359087</td>\n","      <td>0.404126</td>\n","      <td>0.580837</td>\n","      <td>0.558035</td>\n","      <td>0.383766</td>\n","      <td>0.517342</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[101, 15837, 10554, 1010, 12806, 6063, 1010, ...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>0.434182</td>\n","      <td>0.258224</td>\n","      <td>0.251419</td>\n","      <td>0.381444</td>\n","      <td>0.380842</td>\n","      <td>0.388167</td>\n","      <td>0.423407</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[101, 5913, 2998, 4573, 3039, 2000, 5452, 199...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...</td>\n","      <td>0.243421</td>\n","      <td>0.411837</td>\n","      <td>0.380522</td>\n","      <td>0.324291</td>\n","      <td>0.299087</td>\n","      <td>0.293563</td>\n","      <td>0.326980</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>[[101, 2156, 12669, 4819, 2928, 2571, 1005, 10...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>0.426829</td>\n","      <td>0.552968</td>\n","      <td>0.534407</td>\n","      <td>0.476651</td>\n","      <td>0.485527</td>\n","      <td>0.464971</td>\n","      <td>0.554878</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>[[101, 2739, 2651, 1024, 11382, 12096, 6460, 2...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.535876</td>\n","      <td>0.617738</td>\n","      <td>0.545086</td>\n","      <td>0.469628</td>\n","      <td>0.481824</td>\n","      <td>0.452541</td>\n","      <td>0.612522</td>\n","    </tr>\n","    <tr>\n","      <th>600</th>\n","      <td>[[101, 1019, 2477, 2005, 2089, 2603, 1024, 216...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.588346</td>\n","      <td>0.437380</td>\n","      <td>0.484541</td>\n","      <td>0.427071</td>\n","      <td>0.432268</td>\n","      <td>0.478096</td>\n","      <td>0.500349</td>\n","    </tr>\n","    <tr>\n","      <th>601</th>\n","      <td>[[101, 27166, 9818, 7262, 1024, 27166, 9818, 2...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>0.523729</td>\n","      <td>0.617488</td>\n","      <td>0.660028</td>\n","      <td>0.668223</td>\n","      <td>0.653762</td>\n","      <td>0.660923</td>\n","      <td>0.623563</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>[[101, 3534, 4153, 2838, 1999, 2047, 2548, 292...</td>\n","      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...</td>\n","      <td>0.466997</td>\n","      <td>0.514448</td>\n","      <td>0.540849</td>\n","      <td>0.490705</td>\n","      <td>0.506157</td>\n","      <td>0.537049</td>\n","      <td>0.553786</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>603 rows × 11 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75594a31-adca-48ac-a588-c621cf50b3d8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-75594a31-adca-48ac-a588-c621cf50b3d8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-75594a31-adca-48ac-a588-c621cf50b3d8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-62871fac-7c35-4d96-a8b9-0a765889cb7a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62871fac-7c35-4d96-a8b9-0a765889cb7a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-62871fac-7c35-4d96-a8b9-0a765889cb7a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_63121cb2-3b2c-43eb-891a-9b6fb4494128\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_63121cb2-3b2c-43eb-891a-9b6fb4494128 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('X_train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":26}],"source":["scale_feature = [\n","    # X_2\n","    # 1. tech indicator\n","    # 'Open',\n","    # 'High',\n","    # 'Low',\n","    # 'Close',\n","    # 'Volume',\n","    # 'Dividends',\n","    # 'Stock Splits',\n","    'today_return',\n","    # 'Today_trend_cate',\n","    # 'Sma',\n","    # 'Rsi',\n","    # 'Kd',\n","    # 'Ema_12',\n","    # 'Ema_26',\n","    # 'Macd',\n","    # 'sentiment',\n","\n","    # 2. market index\n","    '^DJI',\n","    '^GSPC',\n","    '^NDX',\n","    '^IXIC',\n","    '^SOX',\n","    '^NYA',\n","\n","    # 'datetime'\n","    ]\n","\n","def CustomScaler(X_train, X_val, X_test):\n","  scaler = MinMaxScaler()\n","  for i in scale_feature:\n","\n","    # 對特定欄位進行標準化\n","    X_train_scaled = scaler.fit_transform(X_train[[i]])\n","    X_val_scaled = scaler.transform(X_val[[i]])\n","    X_test_scaled = scaler.transform(X_test[[i]])\n","\n","    # 將標準化後的值重新賦值給 DataFrame\n","    X_train[i] = X_train_scaled\n","    X_val[i] = X_val_scaled\n","    X_test[i] = X_test_scaled\n","\n","  return X_train, X_val, X_test\n","\n","X_train, X_val, X_test = CustomScaler(X_train, X_val, X_test)\n","\n","X_train"]},{"cell_type":"markdown","metadata":{"id":"pGscrhKkRNxo"},"source":["## (6) Check number"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"E6pIRzzhRMoj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866145451,"user_tz":-540,"elapsed":40,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"012c3b6d-30d6-4c6a-c897-49eeede4298c"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Train Count  Train Ratio  Validation Count  Validation Ratio  Test Count  \\\n","0          315     0.522388               106          0.527363          87   \n","1          288     0.477612                95          0.472637         115   \n","\n","   Test Ratio  \n","0    0.430693  \n","1    0.569307  \n"]}],"source":["def calculate_class_stats(y):\n","    class_counts = y.value_counts()\n","    total_samples = len(y)\n","    class_ratios = class_counts / total_samples\n","    return class_counts, class_ratios\n","\n","# 計算類別數量和比例\n","train_class_counts, train_class_ratios = calculate_class_stats(y_train)\n","val_class_counts, val_class_ratios = calculate_class_stats(y_val)\n","test_class_counts, test_class_ratios = calculate_class_stats(y_test)\n","\n","# 創建包含數量和比例的 DataFrame\n","class_stats = pd.DataFrame({\n","    'Train Count': train_class_counts,\n","    'Train Ratio': train_class_ratios,\n","    'Validation Count': val_class_counts,\n","    'Validation Ratio': val_class_ratios,\n","    'Test Count': test_class_counts,\n","    'Test Ratio': test_class_ratios\n","})\n","\n","# 打印 DataFrame\n","print(class_stats)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"SsUxmaKYREFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866145452,"user_tz":-540,"elapsed":33,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"04c8d418-ce09-4990-b106-48d0fbb63789"},"outputs":[{"output_type":"stream","name":"stdout","text":["Time Period\n","From: 2016-01-01T00:00:00\n","To: 2019-12-31T00:00:00 \n","\n","Sample size: 1006\n","Feature: Index(['input_ids', 'attention_mask', 'section_dummy', 'publication_dummy',\n","       'today_return', '^DJI', '^GSPC', '^NDX', '^IXIC', '^SOX', '^NYA'],\n","      dtype='object') \n","\n","Target: excess_return_^GSPC_cate \n","\n","Train: Val: Test = 603 201 202\n"]}],"source":["# Time period\n","print('Time Period')\n","print('From:', time_start)\n","print('To:', time_end, '\\n')\n","\n","# Sample size\n","print('Sample size:', X.shape[0])\n","print('Feature:', X.columns, '\\n')\n","print('Target:', y.name, '\\n')\n","print('Train: Val: Test =', X_train.shape[0], X_val.shape[0], X_test.shape[0])"]},{"cell_type":"markdown","metadata":{"id":"Sd441E-MR_SU"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"dwBFKDyGTyFq"},"source":["## (1) Dataset & Dataloader"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9KAcfnWaRHN6","executionInfo":{"status":"ok","timestamp":1699866145452,"user_tz":-540,"elapsed":22,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# Dataset\n","X_1 =['input_ids', 'attention_mask', 'section_dummy', 'publication_dummy']\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y, config):\n","        # X_1\n","        self.input_ids = X['input_ids']\n","        self.attention_mask = X['attention_mask']\n","        self.section = X['section_dummy']\n","        self.publication = X['publication_dummy']\n","\n","        # X_2\n","        self.X_2 = torch.tensor(X.drop(columns=X_1).values, dtype=torch.float)\n","\n","        # y\n","        self.y = torch.tensor(y.values, dtype=torch.long)\n","\n","        # other setting\n","        self.len = X.shape[0]\n","        self.seq_length = config['seq_length']\n","\n","    def __getitem__(self,idx):\n","        # X_1\n","        input_ids_list = self.input_ids[idx : idx + self.seq_length].tolist() # All to list\n","        input_ids = torch.tensor(input_ids_list) # Then to tensor\n","        attention_mask_list = self.attention_mask[idx : idx + self.seq_length].tolist()\n","        attention_mask = torch.tensor(attention_mask_list)\n","        section_list = self.section[idx : idx + self.seq_length].tolist()\n","        section = torch.tensor(section_list)\n","        publication_list = self.publication[idx : idx + self.seq_length].tolist()\n","        publication = torch.tensor(publication_list)\n","\n","        # X_2\n","        X_2 = self.X_2[idx : idx + self.seq_length]\n","\n","        # 3. y\n","        y = self.y[idx + self.seq_length - 1]\n","\n","        return input_ids, attention_mask, section, publication, X_2, y\n","\n","    def __len__(self):\n","        return self.len - self.seq_length"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"aL5Dlz21VFzy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866154074,"user_tz":-540,"elapsed":8641,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"747e2e03-9e94-4386-a4af-403bea390eb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input IDs shape: torch.Size([32, 5, 124, 32])\n","Attention Mask shape: torch.Size([32, 5, 124, 32])\n","Section shape: torch.Size([32, 5, 124, 9])\n","Publication shape: torch.Size([32, 5, 124, 13])\n","X_2 shape: torch.Size([32, 5, 7])\n","Labels shape: torch.Size([32])\n"]}],"source":["# DataLoader\n","train_dataset = CustomDataset(X_train, y_train, config)\n","val_dataset = CustomDataset(X_val, y_val, config)\n","test_dataset = CustomDataset(X_test, y_test, config)\n","\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","\n","# Check loader output\n","for batch in train_loader:\n","    input_ids, attention_mask, section, publication, X_2, y = batch\n","\n","    # 打印批次数据的形状，以确保它们符合预期\n","    print(\"Input IDs shape:\", input_ids.shape)\n","    print(\"Attention Mask shape:\", attention_mask.shape)\n","    print(\"Section shape:\", section.shape)\n","    print(\"Publication shape:\", publication.shape)\n","    print(\"X_2 shape:\", X_2.shape)\n","    print(\"Labels shape:\", y.shape)\n","\n","    # print(\"Input IDs:\", input_ids)\n","    # print(\"Attention Mask:\", attention_mask)\n","    # print(\"Section:\", section)\n","    # print(\"Publication:\", publication)\n","    # print(\"X_2:\", X_2)\n","    # print(\"Labels:\", y)\n","\n","    break\n"]},{"cell_type":"markdown","metadata":{"id":"_bL0C5M_TtK7"},"source":["## (2) Model Architecture"]},{"cell_type":"markdown","metadata":{"id":"JpX2Eo_HtqMv"},"source":["### 0 Param setting"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gJewmLfayUA1","executionInfo":{"status":"ok","timestamp":1699866154079,"user_tz":-540,"elapsed":42,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["new_config = {\n","    'h_text_size': 5,\n","    'h_c_size': 1,\n","}\n","\n","config.update(new_config)"]},{"cell_type":"markdown","metadata":{"id":"n7nD73XMqu5A"},"source":["### 1 New design"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Zgdm3rwtqzmG","executionInfo":{"status":"ok","timestamp":1699866154081,"user_tz":-540,"elapsed":34,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# New method: C as a scaler + activation function + layer normalization\n","class MyModel(nn.Module):\n","    def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","        super(MyModel, self).__init__()\n","        self.seq_length = config['seq_length']\n","        self.batch_size = batch_size\n","        self.element_size = element_size\n","        self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","                              0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","        self.section_length = section_length\n","        self.publication_length = publication_length\n","        self.config = config\n","\n","        # 1. News\n","        # text\n","        self.base_model = base_model\n","        self.fc1 = nn.Linear(768, config['h_text_size'])\n","\n","        # c\n","        self.fc_h_c = nn.Linear(section_length + publication_length, config['h_c_size'])\n","\n","\n","        # 3. LSTM\n","        self.lstm_1 = nn.LSTM(config['h_text_size'] + X_2_length, 32, dropout=0.1, num_layers=2, batch_first=True, bidirectional=False)\n","        self.sequential = nn.Sequential(\n","            nn.Linear(32, 2)\n","        )\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","        self.batch_norm = nn.BatchNorm1d(config['h_text_size'])\n","\n","\n","\n","    def forward(self, input_ids, attention_mask, section, publication, X_2):\n","        # 1. BERT\n","        flattened_input_ids = input_ids.view(-1, 32)\n","        flattened_attention_mask = attention_mask.view(-1, 32)\n","        flattened_section = section.view(-1, self.section_length)\n","        flattened_publication = publication.view(-1, self.publication_length)\n","\n","        e_list = []\n","        for i in range(0, flattened_input_ids.size(0), self.element_size):\n","          sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","          sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","          sub_section = flattened_section[i:i+self.element_size]\n","          sub_publication = flattened_publication[i:i+self.element_size]\n","\n","          non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","          non_zero_input_ids = sub_input_ids[non_zero_mask]\n","          non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","          non_zero_section = sub_section[non_zero_mask]\n","          non_zero_publication = sub_publication[non_zero_mask]\n","\n","          # input_ids, attention_mask\n","          out = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","          out = out.pooler_output\n","          h_text = self.fc1(out)\n","\n","          # section, publication\n","          dummies = torch.cat([non_zero_section, non_zero_publication], dim=1)\n","          h_c = self.fc_h_c(dummies)\n","          activated_c = self.sigmoid(h_c)\n","\n","          # text * C\n","          scaled_h = h_text * activated_c\n","          batch_norm_h = self.batch_norm(scaled_h)\n","          element_mean = torch.mean(batch_norm_h, dim=0)\n","          e_list.append(element_mean)\n","\n","        temp_tensor = torch.stack(e_list)\n","        b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_text_size'])\n","\n","        # After BERT\n","\n","        h_tech = X_2\n","\n","        h = torch.cat([b_tensor, h_tech], dim=2)\n","\n","        # 3. LSTM\n","        out, _ = self.lstm_1(h)\n","        out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","        final_out = self.sequential(out)\n","\n","        return final_out\n"]},{"cell_type":"markdown","metadata":{"id":"eqSghRXeqrdn"},"source":["2. With C"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"V2kofEKqn2Uk","executionInfo":{"status":"ok","timestamp":1699866154083,"user_tz":-540,"elapsed":32,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# # New structure: With C\n","# class MyModel(nn.Module):\n","#     def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","#         super(MyModel, self).__init__()\n","#         self.seq_length = config['seq_length']\n","#         self.batch_size = batch_size\n","#         self.element_size = element_size\n","#         self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","#                               0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","#         self.section_length = section_length\n","#         self.publication_length = publication_length\n","#         self.config = config\n","\n","#         # 1. News\n","#         # text\n","#         self.base_model = base_model\n","#         self.fc1 = nn.Linear(768, 256)\n","#         self.fc2 = nn.Linear(256, config['h_text_size'])\n","\n","#         # c\n","#         self.fc_h_c = nn.Linear(section_length + publication_length, config['h_c_size'])\n","\n","#         # news (concated)\n","#         # self.fc_h_news = nn.Linear(config['h_text_size'] + config['h_c_size'], config['h_news_size'])\n","#         self.fc_h_news = nn.Linear(config['h_text_size'] + config['h_c_size'], config['h_news_size'])\n","\n","#         # 2. Indicator\n","#         # tech\n","#         # self.fc_h_tech = nn.Linear(X_2_length, config['h_tech_size'])\n","\n","#         # 1&2. converge\n","#         # news + tech\n","#         # self.fc_h = nn.Linear(config['h_news_size'] + X_2_length, config['h_size'])\n","\n","#         # 3. LSTM\n","#         self.lstm_1 = nn.LSTM(config['h_news_size'] + X_2_length, 64, dropout=0.2, num_layers=2, batch_first=True, bidirectional=False)\n","#         self.sequential = nn.Sequential(\n","#             nn.Linear(64, 2)\n","#         )\n","#         self.dropout = nn.Dropout(0.2)\n","\n","\n","#     def forward(self, input_ids, attention_mask, section, publication, X_2):\n","#         # 1. News\n","#         flattened_input_ids = input_ids.view(-1, 32)\n","#         flattened_attention_mask = attention_mask.view(-1, 32)\n","#         flattened_section = section.view(-1, self.section_length)\n","#         flattened_publication = publication.view(-1, self.publication_length)\n","\n","#         e_list = []\n","#         for i in range(0, flattened_input_ids.size(0), self.element_size):\n","#           # 获取当前组的子张量\n","#           sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","#           sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","#           sub_section = flattened_section[i:i+self.element_size]\n","#           sub_publication = flattened_publication[i:i+self.element_size]\n","\n","#           non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","#           non_zero_input_ids = sub_input_ids[non_zero_mask]\n","#           non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","#           non_zero_section = sub_section[non_zero_mask]\n","#           non_zero_publication = sub_publication[non_zero_mask]\n","\n","#           # input_ids, attention_mask\n","#           out = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","#           out = out.pooler_output\n","#           out = self.fc1(out)\n","#           h_text = self.fc2(out)\n","\n","#           # section, publication\n","#           out = torch.cat([non_zero_section, non_zero_publication], dim=1)\n","#           h_c = self.fc_h_c(out)\n","\n","#           # h_news\n","#           out = torch.cat([h_text, h_c], dim=1)\n","#           out = self.fc_h_news(out)\n","#           h_news = self.dropout(out)\n","#           element_mean = torch.mean(h_news, dim=0)\n","#           e_list.append(element_mean)\n","\n","#         temp_tensor = torch.stack(e_list)\n","#         b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_news_size'])\n","\n","#         # 2. Indicator\n","#         # h_tech\n","#         # h_tech = self.fc_h_tech(X_2)\n","#         h_tech = X_2\n","\n","#         # h\n","#         h = torch.cat([b_tensor, h_tech], dim=2)\n","#         # h = self.fc_h(out)\n","\n","#         # 3. LSTM\n","#         out, _ = self.lstm_1(h)\n","#         out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","#         final_out = self.sequential(out)\n","\n","#         return final_out\n"]},{"cell_type":"markdown","metadata":{"id":"AQrDIGG_-Szj"},"source":["2. New method: C as a scaler"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"sb9Ip9mi-RAz","executionInfo":{"status":"ok","timestamp":1699866154086,"user_tz":-540,"elapsed":32,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# # New structure: With C\n","# class MyModel(nn.Module):\n","#     def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","#         super(MyModel, self).__init__()\n","#         self.seq_length = config['seq_length']\n","#         self.batch_size = batch_size\n","#         self.element_size = element_size\n","#         self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","#                               0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","#         self.section_length = section_length\n","#         self.publication_length = publication_length\n","#         self.config = config\n","\n","#         # 1. News\n","#         # text\n","#         self.base_model = base_model\n","#         self.fc1 = nn.Linear(768, 128)\n","#         self.fc2 = nn.Linear(128, config['h_text_size'])\n","\n","#         # c\n","#         self.fc_h_c = nn.Linear(section_length + publication_length, config['h_c_size'])\n","\n","#         # text -> news\n","#         self.fc_h_news = nn.Linear(config['h_text_size'], config['h_news_size'])\n","\n","#         # 3. LSTM\n","#         self.lstm_1 = nn.LSTM(config['h_news_size'] + X_2_length, 32, dropout=0.2, num_layers=2, batch_first=True, bidirectional=False)\n","#         self.sequential = nn.Sequential(\n","#             nn.Linear(32, 2)\n","#         )\n","#         self.relu = nn.ReLU()\n","\n","\n","\n","#     def forward(self, input_ids, attention_mask, section, publication, X_2):\n","#         # 1. News\n","#         flattened_input_ids = input_ids.view(-1, 32)\n","#         flattened_attention_mask = attention_mask.view(-1, 32)\n","#         flattened_section = section.view(-1, self.section_length)\n","#         flattened_publication = publication.view(-1, self.publication_length)\n","\n","#         e_list = []\n","#         for i in range(0, flattened_input_ids.size(0), self.element_size):\n","#           # 获取当前组的子张量\n","#           sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","#           sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","#           sub_section = flattened_section[i:i+self.element_size]\n","#           sub_publication = flattened_publication[i:i+self.element_size]\n","\n","#           non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","#           non_zero_input_ids = sub_input_ids[non_zero_mask]\n","#           non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","#           non_zero_section = sub_section[non_zero_mask]\n","#           non_zero_publication = sub_publication[non_zero_mask]\n","\n","#           # input_ids, attention_mask\n","#           out = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","#           out = out.pooler_output\n","#           out = self.fc1(out)\n","#           h_text = self.fc2(out)\n","\n","#           # section, publication\n","#           out = torch.cat([non_zero_section, non_zero_publication], dim=1)\n","#           out = self.fc_h_c(out)\n","#           h_c = self.relu(out)\n","\n","#           # text * C\n","#           out = h_text * h_c\n","#           h_news = self.fc_h_news(out)\n","#           element_mean = torch.mean(h_news, dim=0)\n","#           e_list.append(element_mean)\n","\n","#         temp_tensor = torch.stack(e_list)\n","#         b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_news_size'])\n","\n","#         h_tech = X_2\n","\n","#         h = torch.cat([b_tensor, h_tech], dim=2)\n","\n","#         # 3. LSTM\n","#         out, _ = self.lstm_1(h)\n","#         out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","#         final_out = self.sequential(out)\n","\n","#         return final_out\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ndJV6wBD_odN","executionInfo":{"status":"ok","timestamp":1699866155046,"user_tz":-540,"elapsed":987,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# # New method: C as a scaler + activation function\n","# class MyModel(nn.Module):\n","#     def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","#         super(MyModel, self).__init__()\n","#         self.seq_length = config['seq_length']\n","#         self.batch_size = batch_size\n","#         self.element_size = element_size\n","#         self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","#                               0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","#         self.section_length = section_length\n","#         self.publication_length = publication_length\n","#         self.config = config\n","\n","#         # 1. News\n","#         # text\n","#         self.base_model = base_model\n","#         self.fc1 = nn.Linear(768, config['h_text_size'])\n","#         # self.fc2 = nn.Linear(64, config['h_text_size'])\n","\n","#         # c\n","#         self.fc_h_c = nn.Linear(section_length + publication_length, config['h_c_size'])\n","\n","#         # text -> news\n","#         self.fc_h_news = nn.Linear(config['h_text_size'], config['h_news_size'])\n","\n","#         # 3. LSTM\n","#         self.lstm_1 = nn.LSTM(config['h_news_size'] + X_2_length, 64, dropout=0.2, num_layers=2, batch_first=True, bidirectional=False)\n","#         self.sequential = nn.Sequential(\n","#             nn.Linear(64, 2)\n","#         )\n","#         self.relu = nn.ReLU()\n","#         self.sigmoid = nn.Sigmoid()\n","\n","\n","\n","#     def forward(self, input_ids, attention_mask, section, publication, X_2):\n","#         # 1. News\n","#         flattened_input_ids = input_ids.view(-1, 32)\n","#         flattened_attention_mask = attention_mask.view(-1, 32)\n","#         flattened_section = section.view(-1, self.section_length)\n","#         flattened_publication = publication.view(-1, self.publication_length)\n","\n","#         e_list = []\n","#         for i in range(0, flattened_input_ids.size(0), self.element_size):\n","#           # 获取当前组的子张量\n","#           sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","#           sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","#           sub_section = flattened_section[i:i+self.element_size]\n","#           sub_publication = flattened_publication[i:i+self.element_size]\n","\n","#           non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","#           non_zero_input_ids = sub_input_ids[non_zero_mask]\n","#           non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","#           non_zero_section = sub_section[non_zero_mask]\n","#           non_zero_publication = sub_publication[non_zero_mask]\n","\n","#           # input_ids, attention_mask\n","#           out = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","#           out = out.pooler_output\n","#           h_text = self.fc1(out)\n","#           # h_text = self.fc2(out)\n","\n","#           # section, publication\n","#           out = torch.cat([non_zero_section, non_zero_publication], dim=1)\n","#           out = self.fc_h_c(out)\n","#           h_c = self.relu(out)\n","\n","#           # text * C\n","#           out = h_text * h_c\n","#           out = self.fc_h_news(out)\n","#           h_news = self.relu(out)\n","\n","#           element_mean = torch.mean(h_news, dim=0)\n","#           e_list.append(element_mean)\n","\n","#         temp_tensor = torch.stack(e_list)\n","#         b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_news_size'])\n","\n","#         h_tech = X_2\n","\n","#         h = torch.cat([b_tensor, h_tech], dim=2)\n","\n","#         # 3. LSTM\n","#         out, _ = self.lstm_1(h)\n","#         out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","#         final_out = self.sequential(out)\n","\n","#         return final_out\n"]},{"cell_type":"markdown","metadata":{"id":"d9jwzVN57zld"},"source":["3. Simplified model\n","without c"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"32Nnc3Dv73Xs","executionInfo":{"status":"ok","timestamp":1699866155048,"user_tz":-540,"elapsed":33,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# # New structure: Save Computation\n","# class MyModel(nn.Module):\n","#     def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","#         super(MyModel, self).__init__()\n","#         self.seq_length = config['seq_length']\n","#         self.batch_size = batch_size\n","#         self.element_size = element_size\n","#         self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","#                               0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","#         self.section_length = section_length\n","#         self.publication_length = publication_length\n","#         self.config = config\n","\n","#         # 1. News\n","#         # text\n","#         self.base_model = base_model\n","#         self.fc1 = nn.Linear(768, 128)\n","#         self.fc2 = nn.Linear(128, config['h_text_size'])\n","\n","\n","#         # 1&2. converge\n","#         # news + tech\n","#         # self.fc_h = nn.Linear(config['h_text_size'] + config['h_tech_size'], config['h_size'])\n","\n","#         # 3. LSTM\n","#         self.lstm_1 = nn.LSTM(config['h_text_size']+X_2_length, 32, dropout=0.2, num_layers=3, batch_first=True, bidirectional=False)\n","#         self.sequential = nn.Sequential(\n","#             nn.Linear(32, 2)\n","#         )\n","#         self.dropout = nn.Dropout(0.2)\n","\n","\n","#     def forward(self, input_ids, attention_mask, section, publication, X_2):\n","#         # 1. News\n","#         flattened_input_ids = input_ids.view(-1, 32)\n","#         flattened_attention_mask = attention_mask.view(-1, 32)\n","#         flattened_section = section.view(-1, self.section_length)\n","#         flattened_publication = publication.view(-1, self.publication_length)\n","\n","#         e_list = []\n","#         for i in range(0, flattened_input_ids.size(0), self.element_size):\n","#           # 获取当前组的子张量\n","#           sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","#           sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","#           sub_section = flattened_section[i:i+self.element_size]\n","#           sub_publication = flattened_publication[i:i+self.element_size]\n","\n","#           non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","#           non_zero_input_ids = sub_input_ids[non_zero_mask]\n","#           non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","#           non_zero_section = sub_section[non_zero_mask]\n","#           non_zero_publication = sub_publication[non_zero_mask]\n","\n","#           # input_ids, attention_mask\n","#           out = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","#           out = out.pooler_output\n","#           out = self.fc1(out)\n","#           out = self.fc2(out)\n","\n","#           element_mean = torch.mean(out, dim=0)\n","#           e_list.append(element_mean)\n","\n","#         temp_tensor = torch.stack(e_list)\n","#         b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_text_size'])\n","\n","#         # 2. Indicator\n","#         # h_tech\n","#         h_tech = X_2\n","\n","#         # h\n","#         h = torch.cat([b_tensor, h_tech], dim=2)\n","\n","#         # 3. LSTM\n","#         out, _ = self.lstm_1(h)\n","#         out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","#         final_out = self.sequential(out)\n","\n","#         return final_out\n"]},{"cell_type":"markdown","metadata":{"id":"2Cu9Rs0uCNYw"},"source":["4. Sequence classifiction model"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"SbytszmbCSSc","executionInfo":{"status":"ok","timestamp":1699866155052,"user_tz":-540,"elapsed":34,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# # New method: C as a scaler + activation function\n","# class MyModel(nn.Module):\n","#     def __init__(self, base_model, config, element_size, section_length, publication_length, X_2_length, batch_size):\n","#         super(MyModel, self).__init__()\n","#         self.seq_length = config['seq_length']\n","#         self.batch_size = batch_size\n","#         self.element_size = element_size\n","#         self.abandon_tensor = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","#                               0, 0, 0, 0, 0, 0, 0, 0], device=device)\n","\n","#         self.section_length = section_length\n","#         self.publication_length = publication_length\n","#         self.config = config\n","\n","#         # 1. News\n","#         # text\n","#         self.base_model = base_model\n","#         # self.fc1 = nn.Linear(768, 64)\n","#         # self.fc2 = nn.Linear(64, config['h_text_size'])\n","\n","#         # c\n","#         self.fc_h_c = nn.Linear(section_length + publication_length, config['h_c_size'])\n","\n","#         # text -> news\n","#         self.fc_h_news = nn.Linear(3, config['h_news_size'])\n","\n","#         # 3. LSTM\n","#         self.lstm_1 = nn.LSTM(config['h_news_size'] + X_2_length, 32, dropout=0.2, num_layers=2, batch_first=True, bidirectional=False)\n","#         self.sequential = nn.Sequential(\n","#             nn.Linear(32, 2)\n","#         )\n","#         self.relu = nn.ReLU()\n","\n","\n","\n","#     def forward(self, input_ids, attention_mask, section, publication, X_2):\n","#         # 1. News\n","#         flattened_input_ids = input_ids.view(-1, 32)\n","#         flattened_attention_mask = attention_mask.view(-1, 32)\n","#         flattened_section = section.view(-1, self.section_length)\n","#         flattened_publication = publication.view(-1, self.publication_length)\n","\n","#         e_list = []\n","#         for i in range(0, flattened_input_ids.size(0), self.element_size):\n","#           # 获取当前组的子张量\n","#           sub_input_ids = flattened_input_ids[i:i+self.element_size]\n","#           sub_attention_mask = flattened_attention_mask[i:i+self.element_size]\n","#           sub_section = flattened_section[i:i+self.element_size]\n","#           sub_publication = flattened_publication[i:i+self.element_size]\n","\n","#           non_zero_mask = (sub_input_ids != 0).any(dim=1)\n","#           non_zero_input_ids = sub_input_ids[non_zero_mask]\n","#           non_zero_attention_mask = sub_attention_mask[non_zero_mask]\n","#           non_zero_section = sub_section[non_zero_mask]\n","#           non_zero_publication = sub_publication[non_zero_mask]\n","\n","#           # input_ids, attention_mask\n","#           h_text = self.base_model(input_ids=non_zero_input_ids, attention_mask=non_zero_attention_mask)\n","#           # h_text = out.pooler_output\n","#           # out = self.fc1(out)\n","#           # h_text = self.fc2(out)\n","\n","#           # section, publication\n","#           out = torch.cat([non_zero_section, non_zero_publication], dim=1)\n","#           out = self.fc_h_c(out)\n","#           h_c = self.relu(out)\n","\n","#           # text * C\n","#           out = h_text.logits * h_c\n","#           h_news = self.fc_h_news(out)\n","#           h_news = self.relu(h_news)\n","#           element_mean = torch.mean(h_news, dim=0)\n","#           e_list.append(element_mean)\n","\n","#         temp_tensor = torch.stack(e_list)\n","#         b_tensor = temp_tensor.view(self.batch_size, self.seq_length, self.config['h_news_size'])\n","\n","#         h_tech = X_2\n","\n","#         h = torch.cat([b_tensor, h_tech], dim=2)\n","\n","#         # 3. LSTM\n","#         out, _ = self.lstm_1(h)\n","#         out = out[:, -1, :]  # Get the last one of LSTM output for prediction of next-term\n","\n","#         final_out = self.sequential(out)\n","\n","#         return final_out\n"]},{"cell_type":"markdown","metadata":{"id":"nzn9Gs2qvN5I"},"source":["## (4) Load Model"]},{"cell_type":"markdown","metadata":{"id":"U5KvkYq4PE59"},"source":["### 1. Load pretrain model"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"W7OjGqgVJ38r","executionInfo":{"status":"ok","timestamp":1699866158211,"user_tz":-540,"elapsed":3191,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["b8ef0139c22d404cbfb9358501b2d6c2","ad54743c42dc4c5f926d0ed4d9b8c8eb","256978a432fa468f80ceabd521b657db","912227674d4645d09c95679dcbede3db","e9cb647edebb428e8e8f3080f5cda9a8","208400943a4e4c23800e0a162b029574","1fe811c40c53452ba968de16a14d0d95","edaed2b2a12044579fc714fbbad63e22","40ef760c7dc9426aba0b2430ef93e5dc","c7a9ede1251b40f788122df20613f851","919d8a69dfce416da04abeb86f7e084b","214dfbc48ed74797af88dc2940e58a05","5d2de26a357845f1b087eb4979aa4a2b","b669096519ac4060b780affeb0ce0643","042c39f3816e4df19b44a775d28faa3d","f693aa4cdf864827aecbce81999f0d1b","56d7bf95b18a49a3bf2ea352e874ff32","8c96aff171a34f91a3174ebacc323fba","7ccbc5f60f4a4946b3378108c3082776","00423a6b891343a3a8a9dda08dcea381","6a21dbe3cc014b5c8da7afc7efc59113","b161d2fed80c4abaafda989e71d405a0"]},"outputId":"8bd8e84c-1756-4bf4-cae5-8fa14cd2fca2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ef0139c22d404cbfb9358501b2d6c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214dfbc48ed74797af88dc2940e58a05"}},"metadata":{}}],"source":["# 載入預訓練模型\n","from transformers import AutoModelForSequenceClassification\n","# base_model = PreModel(base_model)\n","# base_model.load_state_dict(torch.load(config_2['pretrained_model_path']))\n","# bert_config = BertConfig(hidden_dropout_prob=0.2)\n","# model_name = 'ProsusAI/finbert'\n","model_name = 'bert-base-uncased'\n","base_model = BertModel.from_pretrained(model_name)\n","# base_model = BertModel.from_pretrained(model_name, config=bert_config)\n","# base_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Parameter\n","element_size = len(df['input_ids'][0])  # 114\n","section_length = len(df['section_dummy'][0][0])\n","publication_length = len(df['publication_dummy'][0][0])\n","X_2_length = len(feature) - 6\n"]},{"cell_type":"markdown","metadata":{"id":"Rp_BgvqKPIhb"},"source":["### 2. Initiate Model"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"XcR2jjuDrxh6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866161241,"user_tz":-540,"elapsed":3037,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"fa0e6c8d-a8d1-4959-e938-aa09bbcd8465"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyModel(\n","  (base_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc1): Linear(in_features=768, out_features=5, bias=True)\n","  (fc_h_c): Linear(in_features=22, out_features=1, bias=True)\n","  (lstm_1): LSTM(12, 32, num_layers=2, batch_first=True, dropout=0.1)\n","  (sequential): Sequential(\n","    (0): Linear(in_features=32, out_features=2, bias=True)\n","  )\n","  (relu): ReLU()\n","  (sigmoid): Sigmoid()\n","  (batch_norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")"]},"metadata":{},"execution_count":39}],"source":["model = MyModel(base_model, config, element_size, section_length, publication_length, X_2_length, config['batch_size'])\n","\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"S0kKkkcaO5Ma"},"source":["### Extra: Contunue training"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"T3qQOjwKO5bD","executionInfo":{"status":"ok","timestamp":1699866161242,"user_tz":-540,"elapsed":41,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# model = MyModel(base_model, config, section_length, publication_length, X_2_length)\n","# model.load_state_dict(torch.load(config_2['save_path']))\n","# model.to(device)\n","\n","# # 分段訓練\n","# trainer2(model, train_loader, val_loader, config, device)\n","# trainer1(model, train_loader, val_loader, config, device)"]},{"cell_type":"markdown","metadata":{"id":"hW59mzIMvRNd"},"source":["## (5) Require_grad"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"aWIEJzwCR3x0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866161243,"user_tz":-540,"elapsed":37,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}},"outputId":"5fa8f382-062c-4b9f-c8db-ed2272411b9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["base_model.embeddings.word_embeddings.weight False\n","base_model.embeddings.position_embeddings.weight False\n","base_model.embeddings.token_type_embeddings.weight False\n","base_model.embeddings.LayerNorm.weight False\n","base_model.embeddings.LayerNorm.bias False\n","base_model.encoder.layer.0.attention.self.query.weight False\n","base_model.encoder.layer.0.attention.self.query.bias False\n","base_model.encoder.layer.0.attention.self.key.weight False\n","base_model.encoder.layer.0.attention.self.key.bias False\n","base_model.encoder.layer.0.attention.self.value.weight False\n","base_model.encoder.layer.0.attention.self.value.bias False\n","base_model.encoder.layer.0.attention.output.dense.weight False\n","base_model.encoder.layer.0.attention.output.dense.bias False\n","base_model.encoder.layer.0.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.0.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.0.intermediate.dense.weight False\n","base_model.encoder.layer.0.intermediate.dense.bias False\n","base_model.encoder.layer.0.output.dense.weight False\n","base_model.encoder.layer.0.output.dense.bias False\n","base_model.encoder.layer.0.output.LayerNorm.weight False\n","base_model.encoder.layer.0.output.LayerNorm.bias False\n","base_model.encoder.layer.1.attention.self.query.weight False\n","base_model.encoder.layer.1.attention.self.query.bias False\n","base_model.encoder.layer.1.attention.self.key.weight False\n","base_model.encoder.layer.1.attention.self.key.bias False\n","base_model.encoder.layer.1.attention.self.value.weight False\n","base_model.encoder.layer.1.attention.self.value.bias False\n","base_model.encoder.layer.1.attention.output.dense.weight False\n","base_model.encoder.layer.1.attention.output.dense.bias False\n","base_model.encoder.layer.1.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.1.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.1.intermediate.dense.weight False\n","base_model.encoder.layer.1.intermediate.dense.bias False\n","base_model.encoder.layer.1.output.dense.weight False\n","base_model.encoder.layer.1.output.dense.bias False\n","base_model.encoder.layer.1.output.LayerNorm.weight False\n","base_model.encoder.layer.1.output.LayerNorm.bias False\n","base_model.encoder.layer.2.attention.self.query.weight False\n","base_model.encoder.layer.2.attention.self.query.bias False\n","base_model.encoder.layer.2.attention.self.key.weight False\n","base_model.encoder.layer.2.attention.self.key.bias False\n","base_model.encoder.layer.2.attention.self.value.weight False\n","base_model.encoder.layer.2.attention.self.value.bias False\n","base_model.encoder.layer.2.attention.output.dense.weight False\n","base_model.encoder.layer.2.attention.output.dense.bias False\n","base_model.encoder.layer.2.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.2.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.2.intermediate.dense.weight False\n","base_model.encoder.layer.2.intermediate.dense.bias False\n","base_model.encoder.layer.2.output.dense.weight False\n","base_model.encoder.layer.2.output.dense.bias False\n","base_model.encoder.layer.2.output.LayerNorm.weight False\n","base_model.encoder.layer.2.output.LayerNorm.bias False\n","base_model.encoder.layer.3.attention.self.query.weight False\n","base_model.encoder.layer.3.attention.self.query.bias False\n","base_model.encoder.layer.3.attention.self.key.weight False\n","base_model.encoder.layer.3.attention.self.key.bias False\n","base_model.encoder.layer.3.attention.self.value.weight False\n","base_model.encoder.layer.3.attention.self.value.bias False\n","base_model.encoder.layer.3.attention.output.dense.weight False\n","base_model.encoder.layer.3.attention.output.dense.bias False\n","base_model.encoder.layer.3.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.3.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.3.intermediate.dense.weight False\n","base_model.encoder.layer.3.intermediate.dense.bias False\n","base_model.encoder.layer.3.output.dense.weight False\n","base_model.encoder.layer.3.output.dense.bias False\n","base_model.encoder.layer.3.output.LayerNorm.weight False\n","base_model.encoder.layer.3.output.LayerNorm.bias False\n","base_model.encoder.layer.4.attention.self.query.weight False\n","base_model.encoder.layer.4.attention.self.query.bias False\n","base_model.encoder.layer.4.attention.self.key.weight False\n","base_model.encoder.layer.4.attention.self.key.bias False\n","base_model.encoder.layer.4.attention.self.value.weight False\n","base_model.encoder.layer.4.attention.self.value.bias False\n","base_model.encoder.layer.4.attention.output.dense.weight False\n","base_model.encoder.layer.4.attention.output.dense.bias False\n","base_model.encoder.layer.4.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.4.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.4.intermediate.dense.weight False\n","base_model.encoder.layer.4.intermediate.dense.bias False\n","base_model.encoder.layer.4.output.dense.weight False\n","base_model.encoder.layer.4.output.dense.bias False\n","base_model.encoder.layer.4.output.LayerNorm.weight False\n","base_model.encoder.layer.4.output.LayerNorm.bias False\n","base_model.encoder.layer.5.attention.self.query.weight False\n","base_model.encoder.layer.5.attention.self.query.bias False\n","base_model.encoder.layer.5.attention.self.key.weight False\n","base_model.encoder.layer.5.attention.self.key.bias False\n","base_model.encoder.layer.5.attention.self.value.weight False\n","base_model.encoder.layer.5.attention.self.value.bias False\n","base_model.encoder.layer.5.attention.output.dense.weight False\n","base_model.encoder.layer.5.attention.output.dense.bias False\n","base_model.encoder.layer.5.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.5.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.5.intermediate.dense.weight False\n","base_model.encoder.layer.5.intermediate.dense.bias False\n","base_model.encoder.layer.5.output.dense.weight False\n","base_model.encoder.layer.5.output.dense.bias False\n","base_model.encoder.layer.5.output.LayerNorm.weight False\n","base_model.encoder.layer.5.output.LayerNorm.bias False\n","base_model.encoder.layer.6.attention.self.query.weight False\n","base_model.encoder.layer.6.attention.self.query.bias False\n","base_model.encoder.layer.6.attention.self.key.weight False\n","base_model.encoder.layer.6.attention.self.key.bias False\n","base_model.encoder.layer.6.attention.self.value.weight False\n","base_model.encoder.layer.6.attention.self.value.bias False\n","base_model.encoder.layer.6.attention.output.dense.weight False\n","base_model.encoder.layer.6.attention.output.dense.bias False\n","base_model.encoder.layer.6.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.6.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.6.intermediate.dense.weight False\n","base_model.encoder.layer.6.intermediate.dense.bias False\n","base_model.encoder.layer.6.output.dense.weight False\n","base_model.encoder.layer.6.output.dense.bias False\n","base_model.encoder.layer.6.output.LayerNorm.weight False\n","base_model.encoder.layer.6.output.LayerNorm.bias False\n","base_model.encoder.layer.7.attention.self.query.weight False\n","base_model.encoder.layer.7.attention.self.query.bias False\n","base_model.encoder.layer.7.attention.self.key.weight False\n","base_model.encoder.layer.7.attention.self.key.bias False\n","base_model.encoder.layer.7.attention.self.value.weight False\n","base_model.encoder.layer.7.attention.self.value.bias False\n","base_model.encoder.layer.7.attention.output.dense.weight False\n","base_model.encoder.layer.7.attention.output.dense.bias False\n","base_model.encoder.layer.7.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.7.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.7.intermediate.dense.weight False\n","base_model.encoder.layer.7.intermediate.dense.bias False\n","base_model.encoder.layer.7.output.dense.weight False\n","base_model.encoder.layer.7.output.dense.bias False\n","base_model.encoder.layer.7.output.LayerNorm.weight False\n","base_model.encoder.layer.7.output.LayerNorm.bias False\n","base_model.encoder.layer.8.attention.self.query.weight False\n","base_model.encoder.layer.8.attention.self.query.bias False\n","base_model.encoder.layer.8.attention.self.key.weight False\n","base_model.encoder.layer.8.attention.self.key.bias False\n","base_model.encoder.layer.8.attention.self.value.weight False\n","base_model.encoder.layer.8.attention.self.value.bias False\n","base_model.encoder.layer.8.attention.output.dense.weight False\n","base_model.encoder.layer.8.attention.output.dense.bias False\n","base_model.encoder.layer.8.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.8.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.8.intermediate.dense.weight False\n","base_model.encoder.layer.8.intermediate.dense.bias False\n","base_model.encoder.layer.8.output.dense.weight False\n","base_model.encoder.layer.8.output.dense.bias False\n","base_model.encoder.layer.8.output.LayerNorm.weight False\n","base_model.encoder.layer.8.output.LayerNorm.bias False\n","base_model.encoder.layer.9.attention.self.query.weight False\n","base_model.encoder.layer.9.attention.self.query.bias False\n","base_model.encoder.layer.9.attention.self.key.weight False\n","base_model.encoder.layer.9.attention.self.key.bias False\n","base_model.encoder.layer.9.attention.self.value.weight False\n","base_model.encoder.layer.9.attention.self.value.bias False\n","base_model.encoder.layer.9.attention.output.dense.weight False\n","base_model.encoder.layer.9.attention.output.dense.bias False\n","base_model.encoder.layer.9.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.9.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.9.intermediate.dense.weight False\n","base_model.encoder.layer.9.intermediate.dense.bias False\n","base_model.encoder.layer.9.output.dense.weight False\n","base_model.encoder.layer.9.output.dense.bias False\n","base_model.encoder.layer.9.output.LayerNorm.weight False\n","base_model.encoder.layer.9.output.LayerNorm.bias False\n","base_model.encoder.layer.10.attention.self.query.weight False\n","base_model.encoder.layer.10.attention.self.query.bias False\n","base_model.encoder.layer.10.attention.self.key.weight False\n","base_model.encoder.layer.10.attention.self.key.bias False\n","base_model.encoder.layer.10.attention.self.value.weight False\n","base_model.encoder.layer.10.attention.self.value.bias False\n","base_model.encoder.layer.10.attention.output.dense.weight False\n","base_model.encoder.layer.10.attention.output.dense.bias False\n","base_model.encoder.layer.10.attention.output.LayerNorm.weight False\n","base_model.encoder.layer.10.attention.output.LayerNorm.bias False\n","base_model.encoder.layer.10.intermediate.dense.weight False\n","base_model.encoder.layer.10.intermediate.dense.bias False\n","base_model.encoder.layer.10.output.dense.weight False\n","base_model.encoder.layer.10.output.dense.bias False\n","base_model.encoder.layer.10.output.LayerNorm.weight False\n","base_model.encoder.layer.10.output.LayerNorm.bias False\n","base_model.encoder.layer.11.attention.self.query.weight True\n","base_model.encoder.layer.11.attention.self.query.bias True\n","base_model.encoder.layer.11.attention.self.key.weight True\n","base_model.encoder.layer.11.attention.self.key.bias True\n","base_model.encoder.layer.11.attention.self.value.weight True\n","base_model.encoder.layer.11.attention.self.value.bias True\n","base_model.encoder.layer.11.attention.output.dense.weight True\n","base_model.encoder.layer.11.attention.output.dense.bias True\n","base_model.encoder.layer.11.attention.output.LayerNorm.weight True\n","base_model.encoder.layer.11.attention.output.LayerNorm.bias True\n","base_model.encoder.layer.11.intermediate.dense.weight True\n","base_model.encoder.layer.11.intermediate.dense.bias True\n","base_model.encoder.layer.11.output.dense.weight True\n","base_model.encoder.layer.11.output.dense.bias True\n","base_model.encoder.layer.11.output.LayerNorm.weight True\n","base_model.encoder.layer.11.output.LayerNorm.bias True\n","base_model.pooler.dense.weight False\n","base_model.pooler.dense.bias False\n","fc1.weight True\n","fc1.bias True\n","fc_h_c.weight True\n","fc_h_c.bias True\n","lstm_1.weight_ih_l0 True\n","lstm_1.weight_hh_l0 True\n","lstm_1.bias_ih_l0 True\n","lstm_1.bias_hh_l0 True\n","lstm_1.weight_ih_l1 True\n","lstm_1.weight_hh_l1 True\n","lstm_1.bias_ih_l1 True\n","lstm_1.bias_hh_l1 True\n","sequential.0.weight True\n","sequential.0.bias True\n","batch_norm.weight True\n","batch_norm.bias True\n"]}],"source":["# Freeze all layers\n","for param in model.base_model.parameters():\n","  param.requires_grad = False\n","\n","# Unfreeze part of layers\n","# for param in model.base_model.encoder.layer[6].parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.encoder.layer[7].parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.encoder.layer[8].parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.encoder.layer[9].parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.encoder.layer[10].parameters():\n","#     param.requires_grad = True\n","\n","for param in model.base_model.encoder.layer[11].parameters():\n","    param.requires_grad = True\n","\n","# for param in model.base_model.bert.encoder.layer[11].parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.classifier.parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.fc1.parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.fc2.parameters():\n","#     param.requires_grad = True\n","\n","# for param in model.base_model.fc3.parameters():\n","    # param.requires_grad = True\n","\n","# Check requires_grad status\n","for name, param in model.named_parameters():\n","    print(name, param.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"ac2Ve-JWR7EX"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"Kr5YH0wHvMaG"},"source":["New trainer: save based on acc"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"MYmuBnnGYCXa","executionInfo":{"status":"ok","timestamp":1699866161244,"user_tz":-540,"elapsed":23,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["def trainer(model, train_loader, val_loader, config, device):\n","\n","    criterion = config['criterion']\n","\n","    # ----------------------Learning Rate-----------------------\n","    # optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n","\n","    # learning_rates = {\n","    #     'base_model': 1e-5,  # 设置base_model的学习率\n","    #     'base_model_fc': 5e-4,\n","    #     'other_params': 5e-4  # 设置其他参数的学习率\n","    # }\n","\n","    # param_groups = [\n","    #     {'params': model.base_model.parameters(), 'lr': learning_rates['base_model']},\n","    #     {'params': model.fc1.weight, 'lr': learning_rates['base_model_fc']},\n","    #     {'params': model.fc1.bias, 'lr': learning_rates['base_model_fc']},\n","    #     # {'params': model.fc2.weight, 'lr': learning_rates['base_model_fc']},\n","    #     # {'params': model.fc2.bias, 'lr': learning_rates['base_model_fc']},\n","    #     {'params': model.fc_h_c.weight, 'lr': learning_rates['base_model_fc']},\n","    #     {'params': model.fc_h_c.bias, 'lr': learning_rates['base_model_fc']},\n","    #     # {'params': model.fc_h_news.weight, 'lr': learning_rates['base_model_fc']},\n","    #     # {'params': model.fc_h_news.bias, 'lr': learning_rates['base_model_fc']},\n","    #     {'params': model.lstm_1.weight_ih_l0, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.weight_hh_l0, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.bias_ih_l0, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.bias_hh_l0, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.weight_ih_l1, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.weight_hh_l1, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.bias_ih_l1, 'lr': learning_rates['other_params']},\n","    #     {'params': model.lstm_1.bias_hh_l1, 'lr': learning_rates['other_params']},\n","    #     {'params': model.sequential[0].weight, 'lr': learning_rates['other_params']},\n","    #     {'params': model.sequential[0].bias, 'lr': learning_rates['other_params']},\n","    # ]\n","    # optimizer = torch.optim.AdamW(param_groups)\n","    # ----------------------------------------------\n","\n","    writer = SummaryWriter()  # Writer of tensoboard.\n","    n_epochs, best_acc, step, early_stop_count = config['n_epochs'], 0, 0, 0\n","\n","    # 1. Training\n","    for epoch in range(n_epochs):\n","      model.train()  # Set the model to training mode\n","      loss_record = []\n","\n","      train_pbar = tqdm(train_loader, position=0, leave=True)  # tqdm is a package to visualize your training progress.\n","      for input_ids, attention_mask, section, publication, X_2, y in train_loader:\n","        optimizer.zero_grad()  # Set gradient to zero\n","\n","        # Forward pass\n","        input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","        pred = model(input_ids, attention_mask, section, publication, X_2)\n","        loss = criterion(pred, y)\n","        loss.backward()                     # Compute gradient(backpropagation).\n","        optimizer.step()                    # Update parameters.\n","        step += 1\n","        loss_record.append(loss.detach().item())\n","\n","        # Display current epoch number and loss on tqdm progress bar.\n","        train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","        train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","      mean_train_loss = sum(loss_record)/len(loss_record)\n","      writer.add_scalar('Loss/train', mean_train_loss, step)\n","\n","      # 2. Evaluation\n","      model.eval() # Set your model to evaluation mode.\n","      loss_record = []\n","      predicted_labels_list = []\n","      targets_list = []\n","      for input_ids, attention_mask, section, publication, X_2, y in val_loader:\n","          input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","          with torch.no_grad():\n","              pred = model(input_ids, attention_mask, section, publication, X_2)\n","              _, predicted = torch.max(pred, 1)\n","              loss = criterion(pred, y)\n","              predicted_labels_list.extend(predicted.tolist())\n","              targets_list.extend(y.tolist())\n","              loss_record.append(loss.item())\n","      accuracy = accuracy_score(targets_list, predicted_labels_list)\n","\n","      # Mean\n","      mean_valid_loss = sum(loss_record)/len(loss_record)\n","      print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}, Val Acc: {accuracy:.4f}')\n","      writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","      # 3. Judge of saving model\n","      if accuracy > best_acc:\n","          best_acc = accuracy\n","          torch.save(model.state_dict(), config_2['save_path']) # Save your best model\n","          print('Saving model with loss {:.3f}...'.format(best_acc))\n","          early_stop_count = 0\n","      else:\n","          early_stop_count += 1\n","\n","      if early_stop_count >= config['early_stop']:\n","          print('\\nModel is not improving, so we halt the training session.')\n","          return\n"]},{"cell_type":"markdown","metadata":{"id":"eE3MJqOQvI--"},"source":["Old trainer"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"gYCy6aMevHK1","executionInfo":{"status":"ok","timestamp":1699866161246,"user_tz":-540,"elapsed":21,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# def trainer(model, train_loader, val_loader, config, device):\n","\n","#     criterion = config['criterion']\n","\n","#     # ----------------------Learning Rate-----------------------\n","#     # optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n","#     optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n","\n","#     # learning_rates = {\n","#     #     'base_model': 1e-5,  # 设置base_model的学习率\n","#     #     'base_model_fc': 1e-5,\n","#     #     'other_params': 1e-3  # 设置其他参数的学习率\n","#     # }\n","\n","#     # param_groups = [\n","#     #     {'params': model.base_model.parameters(), 'lr': learning_rates['base_model']},\n","#     #     {'params': model.fc1.weight, 'lr': learning_rates['base_model_fc']},\n","#     #     {'params': model.fc1.bias, 'lr': learning_rates['base_model_fc']},\n","#     #     # {'params': model.fc2.weight, 'lr': learning_rates['base_model_fc']},\n","#     #     # {'params': model.fc2.bias, 'lr': learning_rates['base_model_fc']},\n","#     #     {'params': model.fc_h_c.weight, 'lr': learning_rates['base_model_fc']},\n","#     #     {'params': model.fc_h_c.bias, 'lr': learning_rates['base_model_fc']},\n","#     #     # {'params': model.fc_h_news.weight, 'lr': learning_rates['base_model_fc']},\n","#     #     # {'params': model.fc_h_news.bias, 'lr': learning_rates['base_model_fc']},\n","#     #     {'params': model.lstm_1.weight_ih_l0, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.weight_hh_l0, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.bias_ih_l0, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.bias_hh_l0, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.weight_ih_l1, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.weight_hh_l1, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.bias_ih_l1, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.lstm_1.bias_hh_l1, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.sequential[0].weight, 'lr': learning_rates['other_params']},\n","#     #     {'params': model.sequential[0].bias, 'lr': learning_rates['other_params']},\n","#     # ]\n","#     # optimizer = torch.optim.AdamW(param_groups)\n","#     # ----------------------------------------------\n","\n","#     writer = SummaryWriter()  # Writer of tensoboard.\n","#     n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n","\n","#     # 1. Training\n","#     for epoch in range(n_epochs):\n","#       model.train()  # Set the model to training mode\n","#       loss_record = []\n","\n","#       train_pbar = tqdm(train_loader, position=0, leave=True)  # tqdm is a package to visualize your training progress.\n","#       for input_ids, attention_mask, section, publication, X_2, y in train_loader:\n","#         optimizer.zero_grad()  # Set gradient to zero\n","\n","#         # Forward pass\n","#         input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","#         pred = model(input_ids, attention_mask, section, publication, X_2)\n","#         loss = criterion(pred, y)\n","#         loss.backward()                     # Compute gradient(backpropagation).\n","#         optimizer.step()                    # Update parameters.\n","#         step += 1\n","#         loss_record.append(loss.detach().item())\n","\n","#         # Display current epoch number and loss on tqdm progress bar.\n","#         train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","#         train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","#       mean_train_loss = sum(loss_record)/len(loss_record)\n","#       writer.add_scalar('Loss/train', mean_train_loss, step)\n","\n","#       # 2. Evaluation\n","#       model.eval() # Set your model to evaluation mode.\n","#       loss_record = []\n","#       predicted_labels_list = []\n","#       targets_list = []\n","#       for input_ids, attention_mask, section, publication, X_2, y in val_loader:\n","#           input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","#           with torch.no_grad():\n","#               pred = model(input_ids, attention_mask, section, publication, X_2)\n","#               _, predicted = torch.max(pred, 1)\n","#               loss = criterion(pred, y)\n","#               predicted_labels_list.extend(predicted.tolist())\n","#               targets_list.extend(y.tolist())\n","#               loss_record.append(loss.item())\n","#       accuracy = accuracy_score(targets_list, predicted_labels_list)\n","\n","#       # Mean\n","#       mean_valid_loss = sum(loss_record)/len(loss_record)\n","#       print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}, Val Acc: {accuracy:.4f}')\n","#       writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","#       # 3. Judge of saving model\n","#       if mean_valid_loss < best_loss:\n","#           best_loss = mean_valid_loss\n","#           torch.save(model.state_dict(), config_2['save_path']) # Save your best model\n","#           print('Saving model with loss {:.3f}...'.format(best_loss))\n","#           early_stop_count = 0\n","#       else:\n","#           early_stop_count += 1\n","\n","#       if early_stop_count >= config['early_stop']:\n","#           print('\\nModel is not improving, so we halt the training session.')\n","#           return\n"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"hU3BkXDPR5tK","outputId":"1ff29e01-ba3b-43b8-c0f1-8f9da6c41fcb","executionInfo":{"status":"error","timestamp":1699866175402,"user_tz":-540,"elapsed":14176,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/18 [00:00<?, ?it/s]"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-7b3c813c3953>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 全部訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-6c2c59bea0cd>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, train_loader, val_loader, config, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# Compute gradient(backpropagation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-fcae7f3e2ba8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, section, publication, X_2)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;31m# input_ids, attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_zero_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_zero_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0mh_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 4.81 MiB is free. Process 34284 has 14.74 GiB memory in use. Of the allocated memory 13.58 GiB is allocated by PyTorch, and 101.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# 全部訓練\n","trainer(model, train_loader, val_loader, config, device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6s2pWKmMx6L","executionInfo":{"status":"aborted","timestamp":1699866175406,"user_tz":-540,"elapsed":36,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/"]},{"cell_type":"markdown","metadata":{"id":"dRLIhxYobJPn"},"source":["# Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqPpm-mmC6MO","executionInfo":{"status":"aborted","timestamp":1699866175408,"user_tz":-540,"elapsed":36,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":["# Evaluation Dataloader\n","con_train_loader = DataLoader(train_dataset, batch_size=1, shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","con_val_loader = DataLoader(val_dataset, batch_size=1, shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","con_test_loader = DataLoader(test_dataset, batch_size=1, shuffle=config['shuffle'], drop_last=True, pin_memory=True)\n","\n","model = MyModel(base_model, config, element_size, section_length, publication_length, X_2_length, batch_size=1)\n","model.load_state_dict(torch.load(config_2['save_path']))\n","model.to(device)\n","\n","# Evaluation mode\n","model.eval()\n","\n","accuracy_list = []\n","\n","# 1. Train part\n","with torch.no_grad():\n","    predicted_labels_list = []\n","    targets_list = []\n","    for input_ids, attention_mask, section, publication, X_2, y in con_train_loader:\n","        input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","        outputs = model(input_ids, attention_mask, section, publication, X_2)\n","        _, predicted_labels = torch.max(outputs, dim=1)  # 获取每个样本预测的类别索引\n","\n","        predicted_labels_list.extend(predicted_labels.tolist())\n","        targets_list.extend(y.tolist())\n","\n","    # 计算准确率\n","    accuracy = accuracy_score(targets_list, predicted_labels_list)\n","    accuracy_list.append(accuracy)\n","\n","print('=====================================================================================================================')\n","print('Training Result:')\n","print(classification_report(targets_list, predicted_labels_list))\n","print(confusion_matrix(targets_list, predicted_labels_list), '\\n')\n","print('macro_f1: ', f1_score(targets_list, predicted_labels_list, average='macro'))\n","print('weighted_f1: ', f1_score(targets_list, predicted_labels_list, average='weighted'))\n","\n","\n","# 2. Val part\n","with torch.no_grad():\n","    predicted_labels_list = []\n","    targets_list = []\n","    for input_ids, attention_mask, section, publication, X_2, y in con_val_loader:\n","        input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","        outputs = model(input_ids, attention_mask, section, publication, X_2)\n","        _, predicted_labels = torch.max(outputs, dim=1)  # 获取每个样本预测的类别索引\n","\n","        predicted_labels_list.extend(predicted_labels.tolist())\n","        targets_list.extend(y.tolist())\n","\n","    # 计算准确率\n","    accuracy = accuracy_score(targets_list, predicted_labels_list)\n","    accuracy_list.append(accuracy)\n","\n","print('=====================================================')\n","print('Val Result:')\n","print(classification_report(targets_list, predicted_labels_list))\n","print(confusion_matrix(targets_list, predicted_labels_list))\n","print('macro_f1: ', f1_score(targets_list, predicted_labels_list, average='macro'))\n","print('weighted_f1: ', f1_score(targets_list, predicted_labels_list, average='weighted'))\n","\n","# 3. Test part\n","with torch.no_grad():\n","    predicted_labels_list = []\n","    targets_list = []\n","    for input_ids, attention_mask, section, publication, X_2, y in con_test_loader:\n","        input_ids, attention_mask, section, publication, X_2, y = input_ids.to(device), attention_mask.to(device), section.to(device), publication.to(device), X_2.to(device), y.to(device)\n","        outputs = model(input_ids, attention_mask, section, publication, X_2)\n","        _, predicted_labels = torch.max(outputs, dim=1)  # 获取每个样本预测的类别索引\n","\n","        predicted_labels_list.extend(predicted_labels.tolist())\n","        targets_list.extend(y.tolist())\n","\n","    # 计算准确率\n","    accuracy = accuracy_score(targets_list, predicted_labels_list)\n","    accuracy_list.append(accuracy)\n","\n","print('=====================================================')\n","print('Testing Result:')\n","print(classification_report(targets_list, predicted_labels_list))\n","print(confusion_matrix(targets_list, predicted_labels_list))\n","print('macro_f1: ', f1_score(targets_list, predicted_labels_list, average='macro'))\n","print('weighted_f1: ', f1_score(targets_list, predicted_labels_list, average='weighted'))\n","\n","print('=====================================================', '\\n')\n","print(\"Accuracy [Train, Val, Test]: \", accuracy_list, '\\n')\n","print('Config: ', config, '\\n')\n","print('Feature: ', feature)\n","print('time_start: ', time_start, 'time_end: ', time_end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFgOTaztjQ9z","executionInfo":{"status":"aborted","timestamp":1699866175409,"user_tz":-540,"elapsed":36,"user":{"displayName":"Yoga Liu","userId":"16295099566698695483"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b8ef0139c22d404cbfb9358501b2d6c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad54743c42dc4c5f926d0ed4d9b8c8eb","IPY_MODEL_256978a432fa468f80ceabd521b657db","IPY_MODEL_912227674d4645d09c95679dcbede3db"],"layout":"IPY_MODEL_e9cb647edebb428e8e8f3080f5cda9a8"}},"ad54743c42dc4c5f926d0ed4d9b8c8eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_208400943a4e4c23800e0a162b029574","placeholder":"​","style":"IPY_MODEL_1fe811c40c53452ba968de16a14d0d95","value":"Downloading (…)lve/main/config.json: 100%"}},"256978a432fa468f80ceabd521b657db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edaed2b2a12044579fc714fbbad63e22","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40ef760c7dc9426aba0b2430ef93e5dc","value":570}},"912227674d4645d09c95679dcbede3db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a9ede1251b40f788122df20613f851","placeholder":"​","style":"IPY_MODEL_919d8a69dfce416da04abeb86f7e084b","value":" 570/570 [00:00&lt;00:00, 38.7kB/s]"}},"e9cb647edebb428e8e8f3080f5cda9a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"208400943a4e4c23800e0a162b029574":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe811c40c53452ba968de16a14d0d95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edaed2b2a12044579fc714fbbad63e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ef760c7dc9426aba0b2430ef93e5dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7a9ede1251b40f788122df20613f851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919d8a69dfce416da04abeb86f7e084b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"214dfbc48ed74797af88dc2940e58a05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d2de26a357845f1b087eb4979aa4a2b","IPY_MODEL_b669096519ac4060b780affeb0ce0643","IPY_MODEL_042c39f3816e4df19b44a775d28faa3d"],"layout":"IPY_MODEL_f693aa4cdf864827aecbce81999f0d1b"}},"5d2de26a357845f1b087eb4979aa4a2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56d7bf95b18a49a3bf2ea352e874ff32","placeholder":"​","style":"IPY_MODEL_8c96aff171a34f91a3174ebacc323fba","value":"Downloading model.safetensors: 100%"}},"b669096519ac4060b780affeb0ce0643":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ccbc5f60f4a4946b3378108c3082776","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00423a6b891343a3a8a9dda08dcea381","value":440449768}},"042c39f3816e4df19b44a775d28faa3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a21dbe3cc014b5c8da7afc7efc59113","placeholder":"​","style":"IPY_MODEL_b161d2fed80c4abaafda989e71d405a0","value":" 440M/440M [00:01&lt;00:00, 341MB/s]"}},"f693aa4cdf864827aecbce81999f0d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d7bf95b18a49a3bf2ea352e874ff32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c96aff171a34f91a3174ebacc323fba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ccbc5f60f4a4946b3378108c3082776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00423a6b891343a3a8a9dda08dcea381":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a21dbe3cc014b5c8da7afc7efc59113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b161d2fed80c4abaafda989e71d405a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}